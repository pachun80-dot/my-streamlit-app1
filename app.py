import io
import os
import re
import sys
import glob
import unicodedata
import warnings
import pandas as pd
import streamlit as st

# gRPC ê²½ê³  ì–µì œ
os.environ['GRPC_ENABLE_FORK_SUPPORT'] = '0'
os.environ['GRPC_POLL_STRATEGY'] = 'poll'
warnings.filterwarnings('ignore', category=FutureWarning)

from pdf_parser import (
    parse_pdf, split_articles, _detect_lang,
    extract_structured_articles, save_structured_to_excel
)
from html_parser import parse_eu_html_to_dataframe
from translator import translate_batch, _clean_translation_output
from embedder import (
    find_similar_korean,
    find_similar_korean_ai,
    find_similar_korean_batch,
    select_relevant_korean_laws,
)

# â”€â”€ í˜ì´ì§€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="ë²•ë ¹ ë²ˆì—­ ë¹„êµ ë¶„ì„ ì‹œìŠ¤í…œ",
    page_icon="",
    layout="wide",
    initial_sidebar_state="expanded",
)

# â”€â”€ ë°ì´í„° ê²½ë¡œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PROJECT_DIR = os.path.dirname(os.path.abspath(__file__))

if sys.platform == "win32":
    DATA_DIR = os.environ.get("DATA_DIR", r"C:\Users\milhi\Desktop\DATA")
else:
    DATA_DIR = os.environ.get("DATA_DIR", os.path.join(PROJECT_DIR, "DATA"))

COUNTRY_MAP = {
    "ìœ ëŸ½(EPC)": "EPC",
    "ë…ì¼": "GERMANY",
    "í™ì½©": "HONGKONG",
    "ëŒ€ë§Œ": "TAIWAN",
    "ë‰´ì§ˆëœë“œ": "NEWZEALAND",
    "í•œêµ­": "KOREA",
    "ë¯¸êµ­": "USA",
}

KOREA_FOLDER = "KOREA"


def _safe_join(*parts: str) -> str:
    """í•œê¸€ ê²½ë¡œ í˜¸í™˜ì„± ì²˜ë¦¬ (macOS NFD vs Linux NFC).

    macOSì—ì„œ Gitì— ì»¤ë°‹ëœ í•œê¸€ í´ë”ëª…ì€ NFD(ë¶„í•´í˜•)ë¡œ ì €ì¥ë  ìˆ˜ ìˆë‹¤.
    Linux(Streamlit Cloud)ì—ì„œëŠ” NFC(ì¡°í•©í˜•)ì™€ NFDê°€ ì„œë¡œ ë‹¤ë¥¸ ê²½ë¡œë¡œ ì·¨ê¸‰ë˜ë¯€ë¡œ,
    ì§ì ‘ êµ¬ì„±í•œ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•Šì„ ë•Œ ë¶€ëª¨ ë””ë ‰í† ë¦¬ë¥¼ ìŠ¤ìº”í•˜ì—¬ ì¼ì¹˜í•˜ëŠ” í•­ëª©ì„ ì°¾ëŠ”ë‹¤.
    """
    path = os.path.join(*parts)
    if os.path.exists(path):
        return path
    # NFC/NFD ë³€í™˜ ì‹œë„
    for form in ("NFC", "NFD"):
        normalized = unicodedata.normalize(form, path)
        if os.path.exists(normalized):
            return normalized
    # ë¶€ëª¨ ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¦„ ë§¤ì¹­ ì‹œë„
    parent = os.path.dirname(path)
    target = unicodedata.normalize("NFC", os.path.basename(path))
    if os.path.isdir(parent):
        for entry in os.listdir(parent):
            if unicodedata.normalize("NFC", entry) == target:
                return os.path.join(parent, entry)
    return path


# â”€â”€ ì „ë¬¸ UI ìŠ¤íƒ€ì¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PROFESSIONAL_STYLE = """
<style>
/* â”€â”€ í…Œë§ˆ ë³€ìˆ˜ (ë¼ì´íŠ¸ ëª¨ë“œ ê¸°ë³¸) â”€â”€ */
:root {
    --bg-primary: #fefcfb;
    --bg-secondary: #ffffff;
    --bg-tertiary: #fdf8f6;
    --bg-sidebar: linear-gradient(180deg, #fdf8f6 0%, #ffffff 100%);
    --text-primary: #5a4e53;
    --text-heading: #4a3d42;
    --text-secondary: #8a7e84;
    --border-color: #e8ddd8;
    --border-subtle: #f0e8e4;
    --accent: #8b2240;
    --accent-light: #a3324f;
    --accent-dark: #5c1a2a;
    --card-shadow: rgba(0, 0, 0, 0.04);
    --input-bg: #ffffff;
    --tab-hover-bg: #fdf4f0;
    --tab-active-bg: white;
    --table-even-bg: #fafafa;
    --badge-success-bg: #dcfce7;
    --badge-success-text: #166534;
    --badge-warning-bg: #fef3c7;
    --badge-warning-text: #92400e;
    --badge-info-bg: #fce8ed;
    --badge-info-text: #7a1b33;
    --diff-bg: #fff8e1;
    --diff-border: #ffc107;
    --korea-bg: #e8f5e9;
    --korea-border: #4caf50;
    --alert-bg: #ffffff;
}

/* â”€â”€ ë‹¤í¬ ëª¨ë“œ â”€â”€ */
@media (prefers-color-scheme: dark) {
  :root {
    --bg-primary: #1a1a2e;
    --bg-secondary: #252540;
    --bg-tertiary: #2d2d48;
    --bg-sidebar: linear-gradient(180deg, #1e1e35 0%, #252540 100%);
    --text-primary: #ddd6d9;
    --text-heading: #ede7ea;
    --text-secondary: #a89da3;
    --border-color: #3e3e58;
    --border-subtle: #33334a;
    --accent: #d4587a;
    --accent-light: #e06b8a;
    --accent-dark: #a3324f;
    --card-shadow: rgba(0, 0, 0, 0.3);
    --input-bg: #2d2d48;
    --tab-hover-bg: #33334a;
    --tab-active-bg: #2d2d48;
    --table-even-bg: #2a2a44;
    --badge-success-bg: #1a3a2a;
    --badge-success-text: #86efac;
    --badge-warning-bg: #3d2e10;
    --badge-warning-text: #fcd34d;
    --badge-info-bg: #3a1a28;
    --badge-info-text: #f9a8c0;
    --diff-bg: #2e2a1a;
    --diff-border: #b8960e;
    --korea-bg: #1a2e1e;
    --korea-border: #388e3c;
    --alert-bg: #252540;
  }
}

/* ì „ì²´ í°íŠ¸ ë° í…Œë§ˆ ì ìš© */
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');

.stApp {
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
    background-color: var(--bg-primary) !important;
    color: var(--text-primary) !important;
}

/* ë©”ì¸ ì½˜í…ì¸  ì˜ì—­ */
.stApp > header {
    background-color: var(--bg-primary) !important;
}

.main .block-container {
    background-color: var(--bg-primary) !important;
    color: var(--text-primary) !important;
}

/* ëª¨ë“  í…ìŠ¤íŠ¸ ìš”ì†Œ ê¸°ë³¸ ìƒ‰ìƒ */
.stApp p, .stApp span, .stApp label, .stApp div,
.stApp li, .stApp td, .stApp th, .stApp caption {
    color: var(--text-primary) !important;
}

.stApp h1, .stApp h2, .stApp h3, .stApp h4, .stApp h5, .stApp h6 {
    color: var(--text-heading) !important;
}

/* ë©”ì¸ í—¤ë”ëŠ” í°ìƒ‰ í…ìŠ¤íŠ¸ ìœ ì§€ (í¬ë¦¼ìŠ¨ ë°°ê²½) */
.stApp .main-header,
.stApp .main-header h1,
.stApp .main-header p,
.stApp .main-header span,
.stApp .main-header div {
    color: #ffffff !important;
}

/* ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ */
section[data-testid="stSidebar"] {
    background: var(--bg-sidebar) !important;
    border-right: 1px solid var(--border-color);
}

section[data-testid="stSidebar"] .block-container {
    padding-top: 2rem;
}

section[data-testid="stSidebar"] p,
section[data-testid="stSidebar"] span,
section[data-testid="stSidebar"] label,
section[data-testid="stSidebar"] div {
    color: var(--text-primary) !important;
}

/* ë¼ë””ì˜¤ ë²„íŠ¼ / ì²´í¬ë°•ìŠ¤ ë¼ë²¨ */
.stRadio label, .stCheckbox label {
    color: var(--text-primary) !important;
}

/* ì…€ë ‰íŠ¸ë°•ìŠ¤ / ë©€í‹°ì…€ë ‰íŠ¸ í…ìŠ¤íŠ¸ */
[data-baseweb="select"] span,
[data-baseweb="select"] div {
    color: var(--text-primary) !important;
}

/* ë©€í‹°ì…€ë ‰íŠ¸ íƒœê·¸ (ì„ íƒëœ í•­ëª©) */
[data-baseweb="tag"] {
    color: var(--text-primary) !important;
    background-color: var(--bg-tertiary) !important;
}
[data-baseweb="tag"] span {
    color: var(--text-primary) !important;
}

/* ë“œë¡­ë‹¤ìš´ ë©”ë‰´ / íŒì˜¤ë²„ */
[data-baseweb="popover"] {
    background-color: var(--bg-secondary) !important;
}
[data-baseweb="menu"],
[data-baseweb="popover"] ul {
    background-color: var(--bg-secondary) !important;
}
[data-baseweb="menu"] li,
[data-baseweb="menu"] li span,
[data-baseweb="menu"] li div {
    color: var(--text-primary) !important;
    background-color: var(--bg-secondary) !important;
}
[data-baseweb="menu"] li:hover,
[data-baseweb="menu"] li:hover span {
    background-color: var(--bg-tertiary) !important;
}

/* caption í…ìŠ¤íŠ¸ */
.stApp .stCaption, .stApp small,
.stApp [data-testid="stCaptionContainer"] p {
    color: var(--text-secondary) !important;
}

/* ì²´í¬ë°•ìŠ¤ ë‚´ë¶€ í…ìŠ¤íŠ¸ */
.stApp .stCheckbox span,
.stApp .stCheckbox label,
.stApp .stCheckbox div {
    color: var(--text-primary) !important;
}

/* divider */
.stApp hr {
    border-color: var(--border-color) !important;
}

/* warning/info/error ë©”ì‹œì§€ ë‚´ë¶€ í…ìŠ¤íŠ¸ */
.stApp .stAlert p,
.stApp .stAlert span,
.stApp .stAlert div {
    color: inherit !important;
}

/* ë©”ì¸ í—¤ë” */
.main-header {
    background: linear-gradient(135deg, var(--accent-dark) 0%, var(--accent) 50%, var(--accent-light) 100%);
    color: white;
    padding: 2rem 2.5rem;
    border-radius: 12px;
    margin-bottom: 2rem;
    box-shadow: 0 4px 12px -2px rgba(92, 26, 42, 0.25);
}

.main-header h1 {
    margin: 0;
    font-size: 2rem;
    font-weight: 700;
    letter-spacing: -0.02em;
}

.main-header p {
    margin: 0.5rem 0 0 0;
    font-size: 1rem;
    opacity: 0.92;
}

/* ì¹´ë“œ ìŠ¤íƒ€ì¼ */
.info-card {
    background: var(--bg-secondary) !important;
    padding: 1.5rem;
    border-radius: 10px;
    border: 1px solid var(--border-color);
    box-shadow: 0 1px 3px 0 var(--card-shadow);
    margin-bottom: 1rem;
}

.info-card h3 {
    color: var(--text-heading) !important;
    font-size: 1.1rem;
    font-weight: 600;
    margin-bottom: 0.5rem;
}

.info-card p {
    color: var(--text-secondary) !important;
}

/* ìƒíƒœ ë°°ì§€ */
.status-badge {
    display: inline-block;
    padding: 0.25rem 0.75rem;
    border-radius: 9999px;
    font-size: 0.875rem;
    font-weight: 500;
    margin: 0.25rem;
}

.status-success {
    background: var(--badge-success-bg) !important;
    color: var(--badge-success-text) !important;
}

.status-warning {
    background: var(--badge-warning-bg) !important;
    color: var(--badge-warning-text) !important;
}

.status-info {
    background: var(--badge-info-bg) !important;
    color: var(--badge-info-text) !important;
}

/* ë²„íŠ¼ ê°œì„  (í¬ë¦¼ìŠ¨ ë°°ê²½) */
.stApp .stButton > button {
    background: linear-gradient(135deg, var(--accent) 0%, #6e1a33 100%) !important;
    color: #ffffff !important;
    border: none;
    border-radius: 8px;
    padding: 0.6rem 1.5rem;
    font-weight: 600;
    font-size: 0.95rem;
    transition: all 0.2s;
    box-shadow: 0 2px 6px rgba(139, 34, 64, 0.2);
}
.stApp .stButton > button span,
.stApp .stButton > button div,
.stApp .stButton > button p { color: #ffffff !important; }

.stApp .stButton > button:hover {
    background: linear-gradient(135deg, #6e1a33 0%, var(--accent-dark) 100%) !important;
    color: #ffffff !important;
    box-shadow: 0 4px 10px rgba(139, 34, 64, 0.3);
    transform: translateY(-1px);
}

/* ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (ì´ˆë¡ ë°°ê²½) */
.stApp .stDownloadButton > button {
    background: linear-gradient(135deg, #4a6741 0%, #3b5534 100%) !important;
    color: #ffffff !important;
    border: none;
    border-radius: 8px;
    padding: 0.6rem 1.5rem;
    font-weight: 600;
    font-size: 0.95rem;
    box-shadow: 0 2px 4px rgba(74, 103, 65, 0.2);
}
.stApp .stDownloadButton > button span,
.stApp .stDownloadButton > button div,
.stApp .stDownloadButton > button p { color: #ffffff !important; }

.stApp .stDownloadButton > button:hover {
    background: linear-gradient(135deg, #3b5534 0%, #2d422a 100%) !important;
    color: #ffffff !important;
    box-shadow: 0 4px 8px rgba(74, 103, 65, 0.3);
    transform: translateY(-1px);
}

/* ì…ë ¥ í•„ë“œ */
.stSelectbox, .stMultiselect, .stTextInput {
    border-radius: 8px;
}

.stSelectbox > div > div, .stMultiselect > div > div, .stTextInput > div > div {
    border-radius: 8px;
    border-color: var(--border-color);
    background-color: var(--input-bg) !important;
    color: var(--text-primary) !important;
}

.stSelectbox > div > div:focus-within, .stMultiselect > div > div:focus-within {
    border-color: var(--accent);
    box-shadow: 0 0 0 1px var(--accent);
}

/* í…ìŠ¤íŠ¸ ì…ë ¥ */
.stTextInput input, .stTextArea textarea {
    background-color: var(--input-bg) !important;
    color: var(--text-primary) !important;
}

/* ë©”íŠ¸ë¦­ ì¹´ë“œ */
.stMetric {
    background: var(--bg-secondary) !important;
    padding: 1rem;
    border-radius: 10px;
    border: 1px solid var(--border-color);
    box-shadow: 0 1px 2px 0 var(--card-shadow);
}

.stMetric label, .stMetric [data-testid="stMetricValue"],
.stMetric [data-testid="stMetricLabel"] {
    color: var(--text-primary) !important;
}

/* íƒ­ ìŠ¤íƒ€ì¼ */
.stTabs [data-baseweb="tab-list"] {
    gap: 8px;
    background: transparent;
    border-bottom: 2px solid var(--border-color);
}

.stTabs [data-baseweb="tab"] {
    background: transparent;
    border-radius: 8px 8px 0 0;
    padding: 0.75rem 1.5rem;
    font-weight: 500;
    color: var(--text-secondary) !important;
}

.stTabs [data-baseweb="tab"]:hover {
    background: var(--tab-hover-bg);
    color: var(--text-heading) !important;
}

.stTabs [aria-selected="true"] {
    background: var(--tab-active-bg);
    color: var(--accent) !important;
    border-bottom: 3px solid var(--accent);
}

/* í”„ë¡œê·¸ë ˆìŠ¤ ë°” - íŠ¸ë™ (ë°°ê²½) */
.stProgress > div > div > div {
    background-color: var(--border-color) !important;
    border-radius: 9999px;
}
/* í”„ë¡œê·¸ë ˆìŠ¤ ë°” - ì±„ì›€ (ì§„í–‰) */
.stProgress > div > div > div > div {
    background: linear-gradient(90deg, var(--accent) 0%, var(--accent-light) 100%) !important;
    border-radius: 9999px;
}

/* ì•Œë¦¼ ë°•ìŠ¤ */
.stAlert {
    border-radius: 10px;
    border-left: 4px solid;
    background-color: var(--alert-bg) !important;
}

/* ë°ì´í„°í”„ë ˆì„ í…Œì´ë¸” */
.dataframe {
    border: 1px solid var(--border-color) !important;
    border-radius: 8px;
    overflow: hidden;
}

.dataframe thead tr th {
    background: var(--bg-tertiary) !important;
    color: var(--text-heading) !important;
    font-weight: 600 !important;
    border-bottom: 2px solid var(--border-color) !important;
}

.dataframe tbody tr td {
    background: var(--bg-secondary) !important;
    color: var(--text-primary) !important;
}

/* ì‚¬ì´ë“œë°” ë¡œê³  ì˜ì—­ */
.sidebar-logo {
    text-align: center;
    padding: 1.5rem 1rem 1.5rem 1rem;
    margin-bottom: 1.5rem;
    background: linear-gradient(135deg, var(--accent-dark) 0%, var(--accent) 100%);
    border-radius: 10px;
    margin: 0 0.5rem 1.5rem 0.5rem;
}

section[data-testid="stSidebar"] .sidebar-logo h2,
.stApp .sidebar-logo h2 {
    color: #ffffff !important;
    font-size: 1.4rem;
    font-weight: 700;
    margin: 0;
    letter-spacing: 0.02em;
}

section[data-testid="stSidebar"] .sidebar-logo p,
.stApp .sidebar-logo p {
    color: rgba(255,255,255,0.85) !important;
    font-size: 0.82rem;
    margin: 0.3rem 0 0 0;
    font-weight: 400;
}

/* ì„¹ì…˜ í—¤ë” */
.section-header {
    display: flex;
    align-items: center;
    gap: 0.5rem;
    padding: 0 0 0.75rem 0;
    border-bottom: 3px solid var(--accent);
    margin-bottom: 1.5rem;
}

.section-header h3 {
    color: var(--text-heading) !important;
    font-size: 1.3rem;
    font-weight: 700;
    margin: 0;
    letter-spacing: -0.01em;
}

/* expander */
.streamlit-expanderHeader {
    background-color: var(--bg-secondary) !important;
    color: var(--text-primary) !important;
}

.streamlit-expanderContent {
    background-color: var(--bg-secondary) !important;
    color: var(--text-primary) !important;
}

/* status ìœ„ì ¯ */
[data-testid="stStatusWidget"] {
    background-color: var(--bg-secondary) !important;
    color: var(--text-primary) !important;
}
</style>
"""

st.markdown(PROFESSIONAL_STYLE, unsafe_allow_html=True)

# â”€â”€ ë©”ì¸ í—¤ë” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<div class="main-header">
    <h1>ë²•ë ¹ ë²ˆì—­ ë¹„êµ ë¶„ì„ ì‹œìŠ¤í…œ</h1>
    <p>ë‹¤êµ­ì–´ íŠ¹í—ˆë²•ì„ AI ë²ˆì—­í•˜ê³  í•œêµ­ë²•ê³¼ ë¹„êµ ë¶„ì„í•˜ëŠ” ì „ë¬¸ í”Œë«í¼</p>
</div>
""", unsafe_allow_html=True)


# â”€â”€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _list_pdfs(folder: str) -> list[str]:
    """PDF, XML, RTF íŒŒì¼ ëª©ë¡ì„ ë°˜í™˜í•œë‹¤."""
    path = os.path.join(DATA_DIR, folder)
    if not os.path.isdir(path):
        return []
    pdfs = glob.glob(os.path.join(path, "*.pdf"))
    xmls = glob.glob(os.path.join(path, "*.xml"))
    rtfs = glob.glob(os.path.join(path, "*.rtf"))
    return sorted(pdfs + xmls + rtfs)


def _list_result_files() -> list[str]:
    """ë²ˆì—­ ê²°ê³¼ Excel íŒŒì¼ ëª©ë¡ì„ ë°˜í™˜í•œë‹¤."""
    files = []
    # ë²ˆì—­ë¹„êµê²°ê³¼ í´ë”ì—ì„œ Excel íŒŒì¼ë§Œ ë¡œë“œ
    translation_dir = _safe_join(DATA_DIR, "output", "ë²ˆì—­ë¹„êµê²°ê³¼")
    if os.path.isdir(translation_dir):
        files.extend(sorted(glob.glob(os.path.join(translation_dir, "*.xlsx"))))
    # í•˜ìœ„ í˜¸í™˜ì„±: ê¸°ì¡´ output í´ë”ì˜ ë²ˆì—­ íŒŒì¼ë„ í¬í•¨
    output_dir = _safe_join(DATA_DIR, "output")
    if os.path.isdir(output_dir):
        files.extend(sorted(_safe_glob(output_dir, "ë²ˆì—­ë¹„êµ_*.xlsx")))
    # ì¤‘ë³µ ì œê±° (ìˆœì„œ ìœ ì§€)
    return list(dict.fromkeys(files))


def _safe_glob(directory: str, pattern: str) -> list[str]:
    """í•œê¸€ íŒŒì¼ëª… í˜¸í™˜ glob. NFC/NFD ì •ê·œí™” ë¬¸ì œë¥¼ ìš°íšŒí•œë‹¤."""
    results = glob.glob(os.path.join(directory, pattern))
    if results:
        return results
    # glob ì‹¤íŒ¨ ì‹œ os.listdir + fnmatchë¡œ NFC ë¹„êµ
    import fnmatch
    try:
        entries = os.listdir(directory)
    except OSError:
        return []
    nfc_pattern = unicodedata.normalize("NFC", pattern)
    matched = []
    for entry in entries:
        nfc_entry = unicodedata.normalize("NFC", entry)
        if fnmatch.fnmatch(nfc_entry, nfc_pattern):
            matched.append(os.path.join(directory, entry))
    return matched


def _list_structured_excels() -> list[str]:
    """êµ¬ì¡°í™”ë²•ë¥  í´ë” ë‚´ êµ¬ì¡°í™” ì—‘ì…€ íŒŒì¼ ëª©ë¡ (í•œêµ­ë²• ì œì™¸)."""
    structured_dir = _safe_join(DATA_DIR, "output", "êµ¬ì¡°í™”ë²•ë¥ ")
    files = []
    if os.path.isdir(structured_dir):
        files.extend(_safe_glob(structured_dir, "êµ¬ì¡°í™”_*.xlsx"))
    # í•˜ìœ„ í˜¸í™˜ì„±: ê¸°ì¡´ output í´ë”ì˜ êµ¬ì¡°í™” íŒŒì¼ë„ í¬í•¨
    output_dir = _safe_join(DATA_DIR, "output")
    if os.path.isdir(output_dir):
        files.extend(_safe_glob(output_dir, "êµ¬ì¡°í™”_*.xlsx"))

    all_files = sorted(
        [f for f in files if not _basename(f).startswith("~$")],
        key=os.path.getmtime, reverse=True,
    )
    # í•œêµ­ë²• êµ¬ì¡°í™” ì—‘ì…€ ì œì™¸
    nfc = unicodedata.normalize
    return [f for f in all_files
            if "í•œêµ­" not in nfc("NFC", _basename(f)) and "KOREA" not in _basename(f).upper()]


def _list_korea_excels() -> list[str]:
    """êµ¬ì¡°í™”ë²•ë¥  í´ë” ë‚´ í•œêµ­ë²• êµ¬ì¡°í™” ì—‘ì…€ íŒŒì¼ ëª©ë¡."""
    structured_dir = _safe_join(DATA_DIR, "output", "êµ¬ì¡°í™”ë²•ë¥ ")
    files = []
    if os.path.isdir(structured_dir):
        files.extend(_safe_glob(structured_dir, "êµ¬ì¡°í™”_í•œêµ­_*.xlsx"))
    # í•˜ìœ„ í˜¸í™˜ì„±: ê¸°ì¡´ output í´ë”ë„ í™•ì¸
    output_dir = _safe_join(DATA_DIR, "output")
    if os.path.isdir(output_dir):
        files.extend(_safe_glob(output_dir, "êµ¬ì¡°í™”_í•œêµ­_*.xlsx"))

    return sorted(
        [f for f in files if not _basename(f).startswith("~$")],
        key=os.path.getmtime, reverse=True,
    )


def _basename(path: str) -> str:
    return os.path.basename(path)


def _korean_law_name(source: str) -> str:
    """PDF/Excel íŒŒì¼ëª…ì—ì„œ í•œêµ­ë²• ëª…ì¹­ ì¶”ì¶œ. ì˜ˆ: 'êµ¬ì¡°í™”_í•œêµ­_íŠ¹í—ˆë²•(ë²•ë¥ )(...).xlsx' â†’ 'í•œêµ­_íŠ¹í—ˆë²•'"""
    name = source.replace(".pdf", "").replace(".PDF", "").replace(".xlsx", "").replace(".XLSX", "").replace(".rtf", "").replace(".RTF", "")
    if "(" in name:
        name = name[:name.index("(")]
    name = name.strip()

    # "êµ¬ì¡°í™”_í•œêµ­_" ì ‘ë‘ì‚¬ ì œê±°
    if name.startswith("êµ¬ì¡°í™”_í•œêµ­_"):
        name = name.replace("êµ¬ì¡°í™”_í•œêµ­_", "í•œêµ­_", 1)
    elif name.startswith("êµ¬ì¡°í™”_"):
        name = name.replace("êµ¬ì¡°í™”_", "", 1)

    # ì´ë¯¸ "í•œêµ­"ìœ¼ë¡œ ì‹œì‘í•˜ì§€ ì•Šìœ¼ë©´ "í•œêµ­_" ì¶”ê°€
    if not name.startswith("í•œêµ­"):
        name = f"í•œêµ­_{name}"

    return name if name else "í•œêµ­ë²•"


def _clean_text(text: str) -> str:
    """ë²•ë¥  ì¡°ë¬¸ê³¼ ê´€ë ¨ ì—†ëŠ” í…ìŠ¤íŠ¸ì™€ ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ë¥¼ ì œê±°í•œë‹¤."""
    if not text or not isinstance(text, str):
        return ""
    s = text.strip()
    # ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì œê±°
    s = re.sub(r"[*_#`~>|]", "", s)
    s = re.sub(r"\[([^\]]*)\]\([^)]*\)", r"\1", s)  # [text](url) â†’ text
    # í˜ì´ì§€ ë²ˆí˜¸ / ë¨¸ë¦¬ê¸€ / ë°”ë‹¥ê¸€ íŒ¨í„´ ì œê±°
    s = re.sub(r"(?m)^[-â”€â”=]{3,}$", "", s)
    s = re.sub(r"(?m)^Page\s*\d+.*$", "", s, flags=re.IGNORECASE)
    s = re.sub(r"(?m)^-\s*\d+\s*-\s*$", "", s)
    s = re.sub(r"(?m)^åˆ—å°æ™‚é–“[ï¼š:].*$", "", s)
    s = re.sub(r"(?m)^æ‰€æœ‰æ¢æ–‡\s*$", "", s)
    s = re.sub(r"(?m)^æ³•è¦åç¨±[ï¼š:].*$", "", s)
    s = re.sub(r"(?m)^ä¿®æ­£æ—¥æœŸ[ï¼š:].*$", "", s)
    s = re.sub(r"(?m)^ä¿®æ­£â½‡æœŸ[ï¼š:].*$", "", s)
    s = re.sub(r"(?m)^æ³•è¦é¡åˆ¥[ï¼š:].*$", "", s)
    # ì—°ì† ë¹ˆ ì¤„ ì •ë¦¬
    s = re.sub(r"\n{3,}", "\n\n", s)
    return s.strip()


def _esc(text: str) -> str:
    """HTML ì´ìŠ¤ì¼€ì´í”„."""
    return text.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")


# â”€â”€ ê³µí†µ ìŠ¤íƒ€ì¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DETAIL_STYLE = """
<style>
.article-container {
    display: flex;
    margin-bottom: 20px;
    gap: 16px;
}
.article-structure {
    flex: 0 0 280px;
    background: var(--bg-tertiary) !important;
    border: 1px solid var(--border-color);
    border-radius: 8px;
    padding: 14px;
}
.structure-title {
    font-weight: 700;
    font-size: 0.95em;
    color: var(--text-heading) !important;
    margin-bottom: 8px;
    padding-bottom: 6px;
    border-bottom: 1px solid var(--border-color);
    background-color: transparent !important;
}
.structure-content {
    font-size: 0.88em;
    line-height: 1.8;
    color: var(--text-primary) !important;
    background-color: transparent !important;
    white-space: pre-wrap;
    word-break: break-word;
}
.article-row {
    display: flex;
    border: 1px solid var(--border-color);
    border-radius: 8px;
    overflow: hidden;
    flex: 1;
    background-color: var(--bg-secondary) !important;
}
.article-col {
    flex: 1;
    padding: 12px 16px;
    border-right: 2px solid var(--border-color);
    min-width: 0;
    background-color: var(--bg-secondary) !important;
    color: var(--text-primary) !important;
}
.article-col:last-child { border-right: none; }
.article-col-header {
    font-weight: 700; font-size: 0.95em;
    margin-bottom: 8px; padding-bottom: 6px;
    border-bottom: 1px solid var(--border-color);
}
.col-original .article-col-header { color: var(--accent) !important; }
.col-gemini .article-col-header { color: #b8860b !important; }
.col-claude .article-col-header { color: var(--accent-dark) !important; }
.article-col-body {
    font-size: 0.9em; line-height: 1.6;
    white-space: pre-wrap; word-break: break-word;
    color: var(--text-primary) !important; background-color: var(--bg-secondary) !important;
}
.diff-box {
    background: var(--diff-bg) !important; border-left: 4px solid var(--diff-border);
    padding: 10px 14px; margin: 8px 0;
    border-radius: 0 6px 6px 0; font-size: 0.9em; line-height: 1.6;
    color: var(--text-primary) !important;
}
.diff-box strong { color: var(--text-heading) !important; }
.korea-law-box {
    background: var(--korea-bg) !important; border-left: 4px solid var(--korea-border);
    padding: 10px 14px; margin: 8px 0;
    border-radius: 0 6px 6px 0; font-size: 0.9em; line-height: 1.6;
    color: var(--text-primary) !important;
}
.korea-law-box strong { color: var(--text-heading) !important; }
.article-title { font-size: 1.1em; font-weight: 700; margin-bottom: 6px; color: var(--text-heading) !important; }
/* ì „ì²´ ë³´ê¸° í…Œì´ë¸” */
.fullview-table { width: 100%; border-collapse: collapse; }
.fullview-table th {
    background: var(--bg-tertiary) !important; padding: 10px 12px;
    border: 1px solid var(--border-color); text-align: left;
    position: sticky; top: 0; z-index: 1;
    color: var(--text-heading) !important;
}
.fullview-table td {
    padding: 10px 12px; border: 1px solid var(--border-color);
    vertical-align: top; white-space: pre-wrap;
    word-break: break-word; font-size: 0.88em; line-height: 1.6;
    color: var(--text-primary) !important; background-color: var(--bg-secondary) !important;
}
.fullview-table tr:nth-child(even) { background: var(--table-even-bg) !important; }
.fullview-table tr:nth-child(even) td { background: var(--table-even-bg) !important; }
.fullview-table col.col-id { width: 8%; }
.fullview-table col.col-text { width: 30.6%; }
.fullview-table col.col-text-narrow { width: 25%; }
.fullview-table col.col-korean { width: 17%; min-width: 150px; }
</style>
"""

# â”€â”€ ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    # ì‚¬ì´ë“œë°” ë¡œê³ 
    st.markdown("""
    <div class="sidebar-logo">
        <h2>LegalAI</h2>
        <p>ë²•ë ¹ ë²ˆì—­ ë¶„ì„ í”Œë«í¼</p>
    </div>
    """, unsafe_allow_html=True)

    # API í‚¤ ìƒíƒœ
    st.markdown("### ì‹œìŠ¤í…œ ìƒíƒœ")

    gemini_api = st.secrets.get("GOOGLE_API_KEY", "")
    claude_api = st.secrets.get("ANTHROPIC_API_KEY", "")

    gemini_status = "success" if gemini_api else "warning"
    claude_status = "success" if claude_api else "warning"

    st.markdown(f"""
    <div style="margin-bottom: 1rem;">
        <span class="status-badge status-{gemini_status}">
            {'Connected' if gemini_api else 'Not set'} Gemini API
        </span>
        <br>
        <span class="status-badge status-{claude_status}">
            {'Connected' if claude_api else 'Not set'} Claude API
        </span>
    </div>
    """, unsafe_allow_html=True)

    st.divider()

    # ë„¤ë¹„ê²Œì´ì…˜
    st.markdown("### ë©”ë‰´")
    page = st.radio(
        "ê¸°ëŠ¥ ì„ íƒ",
        ["ë²•ë ¹ êµ¬ì¡°í™”", "ë²ˆì—­ ì‹¤í–‰", "ìƒì„¸ë³´ê¸°"],
        label_visibility="collapsed"
    )

    st.divider()

    # ë„ì›€ë§
    with st.expander("ì‚¬ìš© ê°€ì´ë“œ"):
        st.markdown("""
        **1ë‹¨ê³„: ë²•ë ¹ êµ¬ì¡°í™”**
        - PDF/XML íŒŒì¼ì—ì„œ ì¡°ë¬¸ ìë™ ì¶”ì¶œ

        **2ë‹¨ê³„: ë²ˆì—­ ì‹¤í–‰**
        - Gemini / Claude ì´ì¤‘ ë²ˆì—­
        - í•œêµ­ë²• ìœ ì‚¬ ì¡°ë¬¸ ë§¤ì¹­

        **3ë‹¨ê³„: ìƒì„¸ë³´ê¸°**
        - ë²ˆì—­ ë¹„êµ ë¶„ì„ ë° ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
        """)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# í˜ì´ì§€ 1: ë²•ë ¹ êµ¬ì¡°í™” (PDF â†’ êµ¬ì¡°í™” ì—‘ì…€)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if page == "ë²•ë ¹ êµ¬ì¡°í™”":
    st.markdown("""
    <div class="section-header">
        <h3>ë²•ë ¹ êµ¬ì¡°í™”</h3>
    </div>
    """, unsafe_allow_html=True)

    st.markdown("""
    <div class="info-card">
        <p style="margin: 0; color: #64748b;">
            ë²•ë ¹ PDF/XML íŒŒì¼ ë˜ëŠ” HTML URLì„ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ í¸/ì¥/ì ˆ/ì¡°/í•­/í˜¸ ë‹¨ìœ„ë¡œ êµ¬ì¡°í™”í•©ë‹ˆë‹¤.
            êµ¬ì¡°í™”ëœ ë°ì´í„°ëŠ” Excel íŒŒì¼ë¡œ ì €ì¥ë˜ì–´ ë²ˆì—­ ì‘ì—…ì— í™œìš©ë©ë‹ˆë‹¤.
        </p>
    </div>
    """, unsafe_allow_html=True)

    # ì…ë ¥ ë°©ì‹ ì„ íƒ
    input_method = st.radio(
        "ì…ë ¥ ë°©ì‹",
        ["íŒŒì¼ì—ì„œ ì„ íƒ", "HTML URL ì…ë ¥"],
        horizontal=True,
        key="input_method"
    )

    if input_method == "íŒŒì¼ì—ì„œ ì„ íƒ":
        col_s1, col_s2 = st.columns(2)

        with col_s1:
            struct_country = st.selectbox(
                "êµ­ê°€ ì„ íƒ", list(COUNTRY_MAP.keys()), key="struct_country",
            )
            struct_folder = COUNTRY_MAP[struct_country]

        with col_s2:
            struct_pdfs = _list_pdfs(struct_folder)
            if not struct_pdfs:
                st.warning(f"`{DATA_DIR}/{struct_folder}/` í´ë”ì— PDF ë˜ëŠ” XML íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")
            struct_pdf_selected = st.selectbox(
                "ë²•ë ¹ íŒŒì¼ ì„ íƒ", struct_pdfs, format_func=_basename,
                disabled=not struct_pdfs, key="struct_pdf",
            )

        use_ai_titles = st.checkbox(
            "AIë¡œ ì¡°ë¬¸ ì œëª© ì¶”ì¶œ",
            value=False,
            help="Gemini AIê°€ ê° ì¡°ë¬¸ì—ì„œ ì œëª©ì„ ìë™ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤. ê·œì¹™ ê¸°ë°˜ ì¶”ì¶œë¡œë„ ì¶©ë¶„í•˜ë¯€ë¡œ ë³´í†µì€ ë¶ˆí•„ìš”í•©ë‹ˆë‹¤.",
            key="struct_ai_titles",
        )

        struct_run = st.button(
            "êµ¬ì¡°í™” ì‹¤í–‰", type="primary",
            disabled=not struct_pdfs, key="struct_run",
        )
    else:
        # HTML URL ì…ë ¥
        html_url = st.text_input(
            "ë²•ë ¹ HTML URL",
            placeholder="https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:42013A0620(01)",
            help="ìœ ëŸ½ ë²•ë ¹ HTML URLì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: EUR-Lex ì‚¬ì´íŠ¸ì˜ HTML í˜ì´ì§€)",
            key="html_url"
        )

        html_country = st.selectbox(
            "êµ­ê°€ ì„ íƒ",
            ["ìœ ëŸ½(EPC)", "ë…ì¼", "í™ì½©", "ëŒ€ë§Œ", "ë‰´ì§ˆëœë“œ"],
            key="html_country"
        )

        struct_run = st.button(
            "HTML íŒŒì‹± ì‹¤í–‰", type="primary",
            disabled=not html_url, key="html_run",
        )

        # íŒŒì¼ ì„ íƒ ë³€ìˆ˜ ì´ˆê¸°í™” (HTML ëª¨ë“œì—ì„œëŠ” ë¯¸ì‚¬ìš©)
        struct_pdfs = []
        struct_pdf_selected = None
        use_ai_titles = False

    if struct_run:
        output_dir = os.path.join(DATA_DIR, "output")
        os.makedirs(output_dir, exist_ok=True)

        with st.status("ë²•ë ¹ êµ¬ì¡°í™” íŒŒì‹± ì¤‘...", expanded=True) as status:
            # HTML URL ì…ë ¥ ë°©ì‹
            if input_method == "HTML URL ì…ë ¥":
                st.write(f"HTML íŒŒì‹± ì¤‘: {html_url}")
                try:
                    df_structured = parse_eu_html_to_dataframe(html_url)
                    st.write(f"{len(df_structured)}ê°œ í•­ëª© ì¶”ì¶œ (ì¡°/í•­/í˜¸ ë‹¨ìœ„)")

                    # íŒŒì¼ëª… ìƒì„± (URLì—ì„œ ì¶”ì¶œ)
                    import hashlib
                    url_hash = hashlib.md5(html_url.encode()).hexdigest()[:8]
                    base_name = f"{html_country}_HTML_{url_hash}"
                except Exception as e:
                    st.error(f"HTML íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
                    st.stop()

            # íŒŒì¼ ì„ íƒ ë°©ì‹
            elif struct_pdf_selected:
                st.write(f"{_basename(struct_pdf_selected)} ì²˜ë¦¬ ì¤‘...")

                # XML íŒŒì¼ì¸ì§€ PDF íŒŒì¼ì¸ì§€ í™•ì¸
                file_extension = os.path.splitext(struct_pdf_selected)[1].lower()

                if file_extension == '.xml':
                    # XML íŒŒì¼ ì²˜ë¦¬ (ë…ì¼ë²•)
                    from pdf_parser import extract_structured_articles_from_xml
                    st.write("ë…ì¼ ë²•ë ¹ XML íŒŒì‹± ì¤‘...")
                    df_structured = extract_structured_articles_from_xml(
                        struct_pdf_selected,
                        country=struct_country,
                        law_name="íŠ¹í—ˆë²•"  # ê¸°ë³¸ê°’, í•„ìš”ì‹œ UIì—ì„œ ì„ íƒ ê°€ëŠ¥í•˜ë„ë¡ í™•ì¥ ê°€ëŠ¥
                    )
                    st.write(f"{len(df_structured)}ê°œ í•­ëª© ì¶”ì¶œ (ì¡°/í•­ ë‹¨ìœ„)")
                elif file_extension == '.rtf':
                    # RTF íŒŒì¼ ì²˜ë¦¬ (ë¯¸êµ­ë²•)
                    st.write("ë¯¸êµ­ ë²•ë ¹ RTF íŒŒì‹± ì¤‘...")
                    df_structured = extract_structured_articles(
                        struct_pdf_selected,
                        use_ai_titles=use_ai_titles,
                        gemini_api_key=st.secrets.get("GEMINI_API_KEY", "") if use_ai_titles else None,
                    )
                    st.write(f"{len(df_structured)}ê°œ í•­ëª© ì¶”ì¶œ (ì¡°/í•­/í˜¸ ë‹¨ìœ„)")
                else:
                    # PDF íŒŒì¼ ì²˜ë¦¬
                    gemini_api_key = st.secrets.get("GEMINI_API_KEY", "") if use_ai_titles else None

                    if use_ai_titles and gemini_api_key:
                        progress_bar = st.progress(0.0)
                        progress_text = st.empty()

                        def update_progress(current, total, message):
                            progress = current / total if total > 0 else 0
                            progress_bar.progress(progress)
                            progress_text.text(f"{message} ({current}/{total})")
                    else:
                        update_progress = None

                    df_structured = extract_structured_articles(
                        struct_pdf_selected,
                        use_ai_titles=use_ai_titles,
                        gemini_api_key=gemini_api_key,
                        progress_callback=update_progress,
                    )
                    st.write(f"{len(df_structured)}ê°œ í•­ëª© ì¶”ì¶œ (ì¡°/í•­/í˜¸ ë‹¨ìœ„)")

                # íŒŒì¼ëª… ìƒì„±
                base_name = os.path.splitext(os.path.basename(struct_pdf_selected))[0]
            else:
                st.error("íŒŒì¼ì„ ì„ íƒí•˜ê±°ë‚˜ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                st.stop()

            # êµ¬ì¡°í™” íŒŒì¼ì€ êµ¬ì¡°í™”ë²•ë¥  í´ë”ì— ì €ì¥
            structured_dir = _safe_join(DATA_DIR, "output", "êµ¬ì¡°í™”ë²•ë¥ ")
            os.makedirs(structured_dir, exist_ok=True)

            # íŒŒì¼ëª… ìƒì„±
            if input_method == "HTML URL ì…ë ¥":
                # HTML URLì˜ ê²½ìš° ì´ë¯¸ base_nameì´ ìƒì„±ë¨
                base_name_structured = f"êµ¬ì¡°í™”_{base_name}"
            else:
                # íŒŒì¼ í™•ì¥ì ì œê±° (.pdf ë˜ëŠ” .xml)
                base_name_no_ext = _basename(struct_pdf_selected).rsplit('.', 1)[0]
                base_name_structured = f"êµ¬ì¡°í™”_{struct_country}_{base_name_no_ext}"

            excel_path = os.path.join(structured_dir, f"{base_name_structured}.xlsx")
            save_structured_to_excel(df_structured, excel_path)
            st.write(f"ì €ì¥ ì™„ë£Œ: `{excel_path}`")

            status.update(label="êµ¬ì¡°í™” ì™„ë£Œ", state="complete")

        # ë¯¸ë¦¬ë³´ê¸°
        st.subheader("êµ¬ì¡°í™” ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(df_structured.head(20), use_container_width=True, hide_index=True)

        # Excel ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
        import io
        excel_buffer = io.BytesIO()
        with pd.ExcelWriter(excel_buffer, engine="openpyxl") as writer:
            df_structured.to_excel(writer, index=False, sheet_name="ë²•ì¡°ë¬¸")
        excel_data = excel_buffer.getvalue()

        st.download_button(
            label="ğŸ“¥ êµ¬ì¡°í™” Excel ë‹¤ìš´ë¡œë“œ",
            data=excel_data,
            file_name=os.path.basename(excel_path),
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="structured_excel_download"
        )

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# í˜ì´ì§€ 2: ë²ˆì—­ ì‹¤í–‰ (êµ¬ì¡°í™” ì—‘ì…€ â†’ ë²ˆì—­ + í•œêµ­ë²• ë§¤ì¹­)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
elif page == "ë²ˆì—­ ì‹¤í–‰":
    st.markdown("""
    <div class="section-header">
        <h3>AI ë²ˆì—­ ë° ë§¤ì¹­</h3>
    </div>
    """, unsafe_allow_html=True)

    st.markdown("""
    <div class="info-card">
        <p style="margin: 0; color: #64748b;">
            êµ¬ì¡°í™”ëœ ë²•ë ¹ì„ Gemini ë° Claude AIë¡œ ì´ì¤‘ ë²ˆì—­í•˜ê³ , í•œêµ­ íŠ¹í—ˆë²•ì˜ ìœ ì‚¬ ì¡°ë¬¸ì„ ìë™ìœ¼ë¡œ ë§¤ì¹­í•©ë‹ˆë‹¤.
            ë²ˆì—­ ê²°ê³¼ëŠ” Excel íŒŒì¼ë¡œ ì €ì¥ë˜ì–´ ìƒì„¸ ë¹„êµê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.
        </p>
    </div>
    """, unsafe_allow_html=True)

    st.markdown("")  # ì—¬ë°±

    # â”€â”€ ì™¸êµ­ë²• êµ¬ì¡°í™” ì—‘ì…€ ì„ íƒ â”€â”€
    st.markdown("#### ì™¸êµ­ë²• ì„ íƒ")
    foreign_excels = _list_structured_excels()
    # output í´ë”ì˜ ëª¨ë“  ì—‘ì…€ë„ í¬í•¨ (êµ¬ì¡°í™”_ ì ‘ë‘ì‚¬ ì—†ëŠ” ê²ƒë„)
    output_dir = os.path.join(DATA_DIR, "output")
    if os.path.isdir(output_dir):
        all_output_excels = sorted(
            [f for f in glob.glob(os.path.join(output_dir, "*.xlsx"))
             if not _basename(f).startswith("~$")
             and "í•œêµ­" not in _basename(f)
             and "KOREA" not in _basename(f).upper()
             and not _basename(f).startswith("ë²ˆì—­ë¹„êµ_")],
            key=os.path.getmtime, reverse=True,
        )
        # êµ¬ì¡°í™” ì—‘ì…€ ìš°ì„ , ì¤‘ë³µ ì œê±°
        foreign_excels = list(dict.fromkeys(foreign_excels + all_output_excels))

    if not foreign_excels:
        st.warning(
            f"`{output_dir}` í´ë”ì— êµ¬ì¡°í™” ì—‘ì…€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\n\n"
            "'ë²•ë ¹ êµ¬ì¡°í™”' íƒ­ì—ì„œ ë¨¼ì € PDFë¥¼ êµ¬ì¡°í™”í•˜ì„¸ìš”."
        )

    foreign_excel_selected = st.selectbox(
        "ì™¸êµ­ë²• êµ¬ì¡°í™” ì—‘ì…€", foreign_excels, format_func=_basename,
        disabled=not foreign_excels, key="trans_foreign_excel",
    )

    # ì†ŒìŠ¤ ì–¸ì–´ ì„ íƒ
    col_lang, col_service = st.columns(2)
    with col_lang:
        source_lang_option = st.selectbox(
            "ì†ŒìŠ¤ ì–¸ì–´", ["ìë™ ê°ì§€", "ì˜ì–´", "ì¤‘êµ­ì–´"],
            key="trans_source_lang",
            help="íŒŒì¼ëª…ì—ì„œ ìë™ ê°ì§€í•˜ê±°ë‚˜, ìˆ˜ë™ìœ¼ë¡œ ì„ íƒí•˜ì„¸ìš”.",
        )

    # ë²ˆì—­ ì„œë¹„ìŠ¤ ì„ íƒ
    with col_service:
        translation_service = st.selectbox(
            "ë²ˆì—­ ì„œë¹„ìŠ¤",
            ["Gemini + Claude (ì´ì¤‘ ë²ˆì—­)", "Claudeë§Œ", "Geminië§Œ"],
            key="translation_service",
            help="ì‚¬ìš©í•  ë²ˆì—­ ì„œë¹„ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”. API í‚¤ê°€ ì—†ëŠ” ê²½ìš° í•´ë‹¹ ì„œë¹„ìŠ¤ëŠ” ê±´ë„ˆëœë‹ˆë‹¤.",
        )

    st.divider()

    # â”€â”€ í•œêµ­ë²• ì„ íƒ â”€â”€
    st.markdown("#### í•œêµ­ë²• ì„ íƒ (ë‹¤ì¤‘ ê°€ëŠ¥)")
    st.caption("êµ¬ì¡°í™” ì—‘ì…€ê³¼ PDFë¥¼ í˜¼í•©í•˜ì—¬ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    korea_excels = _list_korea_excels()
    korea_pdfs = _list_pdfs(KOREA_FOLDER)

    col_ke, col_kp = st.columns(2)
    with col_ke:
        korea_excel_selected = st.multiselect(
            "í•œêµ­ë²• êµ¬ì¡°í™” ì—‘ì…€",
            korea_excels, format_func=_basename,
            key="trans_korea_excel",
            help="êµ¬ì¡°í™”ëœ ì—‘ì…€ íŒŒì¼ë¡œ í•œêµ­ë²•ì„ ë¡œë“œí•˜ë©´ ì¡°/í•­/í˜¸ ë‹¨ìœ„ë¡œ ë” ì •í™•í•œ ë§¤ì¹­ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
        )
    with col_kp:
        if not korea_pdfs:
            st.warning(f"`{DATA_DIR}/{KOREA_FOLDER}/` í´ë”ì— í•œêµ­ ë²•ë ¹ PDFë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")
        korea_pdf_selected = st.multiselect(
            "í•œêµ­ë²• PDF",
            korea_pdfs, format_func=_basename,
            key="trans_korea_pdf",
        )

    has_korea = bool(korea_excel_selected) or bool(korea_pdf_selected)

    st.divider()

    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì˜µì…˜
    test_mode = st.checkbox(
        "í…ŒìŠ¤íŠ¸ ëª¨ë“œ â€” ì²˜ìŒ 20ì¡°ê¹Œì§€ë§Œ ì²˜ë¦¬",
        value=False,
        key="test_mode",
        help="ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì²˜ìŒ 20ê°œ ì¡°ë¬¸ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤."
    )

    btn_col1, btn_col2, btn_col3 = st.columns(3)
    with btn_col1:
        trans_run = st.button(
            "ë²ˆì—­ ì‹¤í–‰", type="primary",
            disabled=not foreign_excels or not has_korea,
            use_container_width=True, key="trans_run",
        )
    with btn_col2:
        retrans_run = st.button(
            "ì¬ë²ˆì—­ â€” íŠ¹ì • ì¡°ë¬¸",
            disabled=not foreign_excels or not has_korea,
            use_container_width=True, key="retrans_run",
        )
    with btn_col3:
        rematch_run = st.button(
            "ì¬ë§¤ì¹­ â€” ìœ ì‚¬ ì¡°ë¬¸",
            disabled=not foreign_excels or not has_korea,
            use_container_width=True, key="rematch_run",
        )

    # ë²ˆì—­ ì‹¤í–‰ ë²„íŠ¼ í´ë¦­ ì‹œ session stateì— ì €ì¥
    if trans_run:
        st.session_state.translation_started = True
        st.session_state.retranslation_started = False
        st.session_state.rematch_started = False
        # ìƒˆë¡œìš´ ë²ˆì—­ ì‹¤í–‰ ì‹œì‘ - ì„ íƒ state ì´ˆê¸°í™”
        if "proceed_with_choice" in st.session_state:
            del st.session_state.proceed_with_choice
        if "use_existing" in st.session_state:
            del st.session_state.use_existing

    if retrans_run:
        st.session_state.retranslation_started = True
        st.session_state.translation_started = False
        st.session_state.rematch_started = False

    if rematch_run:
        st.session_state.rematch_started = True
        st.session_state.translation_started = False
        st.session_state.retranslation_started = False

    # ë²ˆì—­ì´ ì‹œì‘ëœ ê²½ìš° ì‹¤í–‰
    if st.session_state.get("translation_started", False) and foreign_excel_selected:

        # â”€â”€ ê¸°ì¡´ ë²ˆì—­ ê²°ê³¼ í™•ì¸ â”€â”€
        # íŒŒì¼ëª…ì—ì„œ êµ­ê°€/ë²•ë ¹ëª… ì¶”ì¶œ
        fname = _basename(foreign_excel_selected).replace(".xlsx", "")
        # êµ¬ì¡°í™”_ìœ ëŸ½(EPC)_íŒŒì¼ëª… â†’ ìœ ëŸ½(EPC), íŒŒì¼ëª…
        parts = fname.split("_", 2)
        if len(parts) >= 3 and parts[0] == "êµ¬ì¡°í™”":
            trans_country = parts[1]
            trans_law_name = parts[2]
        elif len(parts) >= 2 and parts[0] == "êµ¬ì¡°í™”":
            trans_country = parts[1]
            trans_law_name = parts[1]
        else:
            trans_country = fname
            trans_law_name = fname

        # í…ŒìŠ¤íŠ¸ ëª¨ë“œì¼ ê²½ìš° íŒŒì¼ëª…ì— í‘œì‹œ
        test_suffix = "_í…ŒìŠ¤íŠ¸" if test_mode else ""
        base_name = f"ë²ˆì—­ë¹„êµ_{trans_country}_{trans_law_name}{test_suffix}"

        existing_csv = None
        for search_dir in [_safe_join(DATA_DIR, "output"), PROJECT_DIR]:
            for ext in [".csv", ".xlsx"]:
                candidate = _safe_join(search_dir, f"{base_name}{ext}")
                if os.path.exists(candidate):
                    existing_csv = candidate
                    break
            if existing_csv:
                break

        if existing_csv:
            st.warning("ê¸°ì¡´ ë²ˆì—­ ê²°ê³¼ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.")

            df_existing = None
            if existing_csv.endswith((".xlsx", ".xls")):
                try:
                    df_existing = pd.read_excel(existing_csv)
                except Exception:
                    pass
            else:
                for enc in ["utf-8-sig", "utf-8"]:
                    try:
                        df_existing = pd.read_csv(existing_csv, encoding=enc)
                        break
                    except (UnicodeDecodeError, UnicodeError):
                        continue

            if df_existing is not None:
                st.info(f"íŒŒì¼: `{_basename(existing_csv)}`")

                info_col1, info_col2, info_col3 = st.columns(3)
                with info_col1:
                    st.metric("ì´ ì¡°ë¬¸ ìˆ˜", len(df_existing))
                with info_col2:
                    if "ë§¤ì¹­ ì ìˆ˜" in df_existing.columns:
                        scores = pd.to_numeric(df_existing["ë§¤ì¹­ ì ìˆ˜"], errors="coerce")
                        avg_score = scores.mean()
                        st.metric("í‰ê·  ë§¤ì¹­ ì ìˆ˜", f"{avg_score:.3f}" if pd.notna(avg_score) else "-")
                with info_col3:
                    if "í•´ì„ ì°¨ì´" in df_existing.columns:
                        diff_count = df_existing["í•´ì„ ì°¨ì´"].notna().sum()
                        st.metric("í•´ì„ ì°¨ì´ ë¶„ì„", f"{diff_count}ê±´")

                st.subheader("ê¸°ì¡´ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5ê°œ ì¡°ë¬¸)")
                preview_df = df_existing.head(5).copy()
                for col in ["ì›ë¬¸", "Gemini ë²ˆì—­", "Claude ë²ˆì—­"]:
                    if col in preview_df.columns:
                        preview_df[col] = preview_df[col].apply(
                            lambda x: str(x)[:100] + "..." if pd.notna(x) and len(str(x)) > 100 else x
                        )
                st.dataframe(preview_df, use_container_width=True, hide_index=True)

                st.divider()

                st.subheader("ë²ˆì—­ ì‹¤í–‰ ë°©ì‹ ì„ íƒ")
                choice = st.radio(
                    "ì–´ë–»ê²Œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
                    [
                        "ê¸°ì¡´ ë²ˆì—­ ê²°ê³¼ ì‚¬ìš© (ë¹ ë¦„, ë¹„ìš© ì ˆê°)",
                        "ìƒˆë¡œ ë²ˆì—­ ì‹¤í–‰ (API í˜¸ì¶œ, ì‹œê°„ ì†Œìš”)"
                    ],
                    key="use_existing_choice",
                    help="ê¸°ì¡´ ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ë©´ API í˜¸ì¶œ ì—†ì´ ì¦‰ì‹œ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
                use_existing = choice.startswith("ê¸°ì¡´")

                st.divider()
                col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 2])
                with col_btn1:
                    if st.button("ì„ íƒ í™•ì •", type="primary", use_container_width=True, key="confirm_choice_btn"):
                        st.session_state.proceed_with_choice = True
                        st.session_state.use_existing = use_existing
                with col_btn2:
                    if st.button("ì·¨ì†Œ", use_container_width=True, key="cancel_choice_btn"):
                        if "proceed_with_choice" in st.session_state:
                            del st.session_state.proceed_with_choice
                        if "use_existing" in st.session_state:
                            del st.session_state.use_existing
                        st.info("ë¶„ì„ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.stop()

                if not st.session_state.get("proceed_with_choice", False):
                    st.info("ìœ„ì—ì„œ ì˜µì…˜ì„ ì„ íƒí•˜ê³  'ì„ íƒ í™•ì •' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
                    st.stop()

                # session_stateì—ì„œ ì„ íƒ ê°’ ê°€ì ¸ì˜¤ê¸°
                use_existing = st.session_state.get("use_existing", True)

                if use_existing:
                    st.success(f"ê¸°ì¡´ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ: {len(df_existing)}ê±´")
                    if "ì¡°ë¬¸" in df_existing.columns:
                        df_existing = df_existing[df_existing["ì¡°ë¬¸"] != "ì „ë¬¸"]
                    st.dataframe(df_existing, use_container_width=True, hide_index=True, height=400)
                    st.info("'ìƒì„¸ë³´ê¸°' íƒ­ì—ì„œ ìƒì„¸ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.")
                    st.stop()
            else:
                st.error("ê¸°ì¡´ ê²°ê³¼ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ë²ˆì—­ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.")

        # ê¸°ì¡´ ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš° ìƒˆë¡œ ë²ˆì—­ ì‹¤í–‰
        if not st.session_state.get("use_existing", False):
            # â”€â”€ 1) ì™¸êµ­ë²• ì—‘ì…€ ë¡œë“œ â”€â”€
            with st.status("ì™¸êµ­ë²• êµ¬ì¡°í™” ì—‘ì…€ ë¡œë“œ ì¤‘...", expanded=True) as status:
                try:
                    df_foreign = pd.read_excel(foreign_excel_selected)
                    st.write(f"{_basename(foreign_excel_selected)} ë¡œë“œ: {len(df_foreign)}ê±´")
                except Exception as e:
                    st.error(f"ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨: {e}")
                    st.stop()

                # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
                required_cols = ["ì¡°ë¬¸ë²ˆí˜¸", "ì›ë¬¸"]
                missing_cols = [c for c in required_cols if c not in df_foreign.columns]
                if missing_cols:
                    st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_cols}")
                    st.stop()

                # NaNì„ ë¹ˆ ë¬¸ìì—´ë¡œ ì±„ìš°ê¸°
                for col in ["í¸", "ì¥", "ì ˆ", "ì¡°ë¬¸ì œëª©", "í•­", "í˜¸"]:
                    if col in df_foreign.columns:
                        df_foreign[col] = df_foreign[col].fillna("").astype(str)
                    else:
                        df_foreign[col] = ""

                # ì¡°ë¬¸ ë¦¬ìŠ¤íŠ¸ ìƒì„±
                foreign_articles = []
                for _, row in df_foreign.iterrows():
                    article_id = f"{row['ì¡°ë¬¸ë²ˆí˜¸']}"
                    if row['í•­']:
                        article_id += f"-{row['í•­']}"
                    if row['í˜¸']:
                        article_id += f"-{row['í˜¸']}"

                    # ì›ë¬¸ì´ NaNì´ê±°ë‚˜ ë¹ˆ ê°’ì´ë©´ ê±´ë„ˆë›°ê¸°
                    text = str(row["ì›ë¬¸"]) if pd.notna(row["ì›ë¬¸"]) else ""
                    if not text.strip():
                        continue

                    foreign_articles.append({
                        "id": article_id,
                        "text": text,
                        "í¸": str(row.get("í¸", "")) if pd.notna(row.get("í¸")) else "",
                        "ì¥": str(row.get("ì¥", "")) if pd.notna(row.get("ì¥")) else "",
                        "ì ˆ": str(row.get("ì ˆ", "")) if pd.notna(row.get("ì ˆ")) else "",
                        "ì¡°ë¬¸ë²ˆí˜¸": str(row["ì¡°ë¬¸ë²ˆí˜¸"]) if pd.notna(row["ì¡°ë¬¸ë²ˆí˜¸"]) else "",
                        "ì¡°ë¬¸ì œëª©": str(row.get("ì¡°ë¬¸ì œëª©", "")) if pd.notna(row.get("ì¡°ë¬¸ì œëª©")) else "",
                        "í•­": str(row.get("í•­", "")) if pd.notna(row.get("í•­")) else "",
                        "í˜¸": str(row.get("í˜¸", "")) if pd.notna(row.get("í˜¸")) else "",
                    })

                # í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì²˜ìŒ 20ê°œ ì¡°ë¬¸ê¹Œì§€ë§Œ ì²˜ë¦¬
                if test_mode:
                    unique_articles = []
                    seen_article_nums = set()
                    for art in foreign_articles:
                        art_num = art.get("ì¡°ë¬¸ë²ˆí˜¸", "")
                        if art_num not in seen_article_nums:
                            seen_article_nums.add(art_num)
                        if len(seen_article_nums) <= 20:
                            unique_articles.append(art)
                        else:
                            break
                    foreign_articles = unique_articles
                    st.info(f"í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì²˜ìŒ 20ê°œ ì¡°ë¬¸ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤ (ì´ {len(foreign_articles)}ê°œ í•­ëª©)")

                # ì†ŒìŠ¤ ì–¸ì–´ ê²°ì •
                if source_lang_option == "ì˜ì–´":
                    source_lang = "english"
                elif source_lang_option == "ì¤‘êµ­ì–´":
                    source_lang = "chinese"
                else:
                    source_lang = _detect_lang(foreign_excel_selected)

                st.write(f"ì†ŒìŠ¤ ì–¸ì–´: {source_lang}")
                status.update(label="ì™¸êµ­ë²• ë¡œë“œ ì™„ë£Œ", state="complete")

            # â”€â”€ 2) í•œêµ­ë²• ë¡œë“œ (AI ë§¤ì¹­ìš©) â”€â”€
            with st.status("í•œêµ­ ë²•ë ¹ ë¡œë“œ ì¤‘...", expanded=True) as status:
                all_korea_articles = []

                # êµ¬ì¡°í™” ì—‘ì…€ì—ì„œ í•œêµ­ë²• ë¡œë“œ (ì¡° ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”)
                for excel_path in korea_excel_selected:
                    try:
                        df_korea = pd.read_excel(excel_path)
                        source_name = _basename(excel_path)

                        # ì¡° ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”
                        korea_by_article = {}
                        for _, row in df_korea.iterrows():
                            article_num = row.get('ì¡°ë¬¸ë²ˆí˜¸', '')
                            if pd.notna(article_num) and str(article_num).strip():
                                article_num = str(article_num)

                                # ì¡°ë¬¸ë²ˆí˜¸ê°€ ì²˜ìŒ ë‚˜ì˜¨ ê²½ìš°ì—ë§Œ ì´ˆê¸°í™”
                                if article_num not in korea_by_article:
                                    korea_by_article[article_num] = {
                                        'rows': [],
                                        'title': str(row.get('ì¡°ë¬¸ì œëª©', '')).strip() if pd.notna(row.get('ì¡°ë¬¸ì œëª©')) else ""
                                    }

                                # í•´ë‹¹ ì¡°ë¬¸ì˜ ëª¨ë“  í•­/í˜¸/ëª© í–‰ ìˆ˜ì§‘
                                text = str(row.get("ì›ë¬¸", "")).strip()
                                if text:
                                    korea_by_article[article_num]['rows'].append(text)

                        # ì¡°ë¬¸ ë‹¨ìœ„ë¡œ all_korea_articlesì— ì¶”ê°€
                        for article_num, data in korea_by_article.items():
                            combined_text = "\n".join(data['rows'])
                            all_korea_articles.append({
                                "id": article_num,
                                "text": combined_text,
                                "source": source_name,
                                "title": data['title'],
                            })

                        st.write(f"{source_name}: {len(korea_by_article)}ê°œ ì¡°ë¬¸")
                    except Exception as e:
                        st.warning(f"ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨ ({_basename(excel_path)}): {e}")

                # PDFì—ì„œ í•œêµ­ë²• ë¡œë“œ
                for kp in korea_pdf_selected:
                    k_text = parse_pdf(kp)
                    k_articles = split_articles(k_text, lang="korean")
                    for a in k_articles:
                        a["source"] = _basename(kp)
                    all_korea_articles.extend(k_articles)
                    st.write(f"{_basename(kp)}: {len(k_articles)}ê°œ ì¡°ë¬¸")

                if not all_korea_articles:
                    st.error("í•œêµ­ë²• ì¡°ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. ì—‘ì…€ ë˜ëŠ” PDFë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    st.stop()

                # AI ë§¤ì¹­ìš© ê°„ë‹¨í•œ ì¸ë±ìŠ¤ (ì„ë² ë”© ì—†ìŒ)
                korea_index = {"articles": all_korea_articles}
                st.write(f"í•œêµ­ë²• ì´ {len(all_korea_articles)}ê°œ ì¡°ë¬¸ ë¡œë“œ ì™„ë£Œ")
                status.update(label="í•œêµ­ ë²•ë ¹ ë¡œë“œ ì™„ë£Œ", state="complete")

            # â”€â”€ 3) ë²ˆì—­ ì‹¤í–‰ â”€â”€
            st.subheader("ë²ˆì—­ ì§„í–‰")
            progress_bar = st.progress(0, text="ë²ˆì—­ ì¤€ë¹„ ì¤‘...")

            def _update_progress(current, total):
                progress_bar.progress(current / total, text=f"ë²ˆì—­ ì¤‘... ({current}/{total})")

            # ë²ˆì—­ ì„œë¹„ìŠ¤ ì„ íƒì— ë”°ë¼ í”Œë˜ê·¸ ì„¤ì •
            use_gemini = "Gemini" in translation_service
            use_claude = "Claude" in translation_service

            translated = translate_batch(
                foreign_articles,
                source_lang=source_lang,
                progress_callback=_update_progress,
                group_by_article=True,
                use_gemini=use_gemini,
                use_claude=use_claude,
            )
            progress_bar.progress(1.0, text="ë²ˆì—­ ì™„ë£Œ!")

            # â”€â”€ 4) ìœ ì‚¬ í•œêµ­ë²• AI ë§¤ì¹­ â”€â”€
            st.subheader("í•œêµ­ë²• ìœ ì‚¬ ì¡°ë¬¸ ë§¤ì¹­")

            with st.status("ê´€ë ¨ í•œêµ­ë²• ì„ íƒ ì¤‘...", expanded=True) as status:
                korea_law_sources = sorted(set(
                    a.get("source", "") for a in all_korea_articles if a.get("source")
                ))
                sample_text = ""
                for item in translated:
                    if item["id"] != "ì „ë¬¸" and not item["id"].endswith("(ì‚­ì œ)"):
                        sample_text = item.get("gemini", "") or item.get("claude", "")
                        break

                relevant_sources = select_relevant_korean_laws(
                    _basename(foreign_excel_selected), sample_text, korea_law_sources,
                )
                for src in relevant_sources:
                    st.write(f"ê´€ë ¨ í•œêµ­ë²•: {_korean_law_name(src)}")
                status.update(label=f"ê´€ë ¨ í•œêµ­ë²• {len(relevant_sources)}ê°œ ì„ íƒ ì™„ë£Œ", state="complete")

            # ì¡°ë¬¸ ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”
            from collections import defaultdict
            article_groups = defaultdict(list)
            for item in translated:
                article_num = item.get("ì¡°ë¬¸ë²ˆí˜¸", item["id"])
                article_groups[article_num].append(item)

            match_progress = st.progress(0, text="í•œêµ­ë²• ì¡°ë¬¸ ì¼ê´„ ë§¤ì¹­ ì¤‘...")

            # ì¼ê´„ ë§¤ì¹­ì„ ìœ„í•œ ì¡°ë¬¸ ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„
            batch_articles = []
            for article_num, group in article_groups.items():
                if article_num != "ì „ë¬¸" and not article_num.endswith("(ì‚­ì œ)"):
                    first_item = group[0]
                    combined_original = str(first_item.get("original", ""))
                    combined_translated = str(first_item.get("gemini", "")) or str(first_item.get("claude", ""))
                    article_title = first_item.get("ì¡°ë¬¸ì œëª©", "")

                    batch_articles.append({
                        'id': article_num,
                        'text': combined_original,
                        'ì¡°ë¬¸ì œëª©': article_title,
                        'translated': combined_translated
                    })

            # ì¼ê´„ ë§¤ì¹­ ì‹¤í–‰ (í•œ ë²ˆì˜ API í˜¸ì¶œ)
            match_progress.progress(0.5, text="í•œêµ­ë²• ì¡°ë¬¸ ì¼ê´„ ë§¤ì¹­ ì¤‘... (AI ì²˜ë¦¬ ì¤‘)")
            batch_results = find_similar_korean_batch(
                batch_articles,
                korea_index,
                relevant_law_sources=relevant_sources
            )

            # ë””ë²„ê¹…: ë§¤ì¹­ ê²°ê³¼ í™•ì¸
            st.write(f"batch_results í‚¤: {list(batch_results.keys())[:10]}")
            st.write(f"article_groups í‚¤: {list(article_groups.keys())[:10]}")
            matched_count = sum(1 for v in batch_results.values() if v)
            st.write(f"ë§¤ì¹­ëœ ì¡°ë¬¸ ìˆ˜: {matched_count}/{len(batch_results)}")

            # ë§¤ì¹­ ê²°ê³¼ë¥¼ ê° ì¡°ë¬¸ì— í• ë‹¹
            for article_num, group in article_groups.items():
                if article_num == "ì „ë¬¸" or article_num.endswith("(ì‚­ì œ)"):
                    for item in group:
                        item["similar_korean"] = []
                else:
                    # ì¼ê´„ ë§¤ì¹­ ê²°ê³¼ì—ì„œ ê°€ì ¸ì˜¤ê¸°
                    # í‚¤ ë§¤ì¹­: "Article 1" â†’ "1", "Rule 1" â†’ "1" ë“±
                    search_key = str(article_num)
                    # "Article ", "Rule ", "ç¬¬" ë“±ì˜ ì ‘ë‘ì‚¬ ì œê±°
                    for prefix in ["Article ", "Rule ", "ç¬¬"]:
                        if search_key.startswith(prefix):
                            search_key = search_key[len(prefix):]
                            break
                    # "æ¢" ì ‘ë¯¸ì‚¬ ì œê±°
                    search_key = search_key.rstrip("æ¢")

                    matches = batch_results.get(search_key, [])
                    if not matches:
                        # ì›ë˜ í‚¤ë¡œë„ ì‹œë„
                        matches = batch_results.get(str(article_num), [])

                    for item in group:
                        item["similar_korean"] = matches

            match_progress.progress(1.0, text="í•œêµ­ë²• ì¡°ë¬¸ ë§¤ì¹­ ì™„ë£Œ")

            # â”€â”€ 5) ê²°ê³¼ êµ¬ì„± ë° ì €ì¥ â”€â”€
            st.subheader("ë¶„ì„ ê²°ê³¼")

            rows_full = []
            rows_display = []

            # ì¡°ë¬¸ ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”í•´ì„œ í‘œì‹œ
            for article_num, group in article_groups.items():
                # ì²« ë²ˆì§¸ í•­ëª©ì—ì„œ ê³µí†µ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                first_item = group[0]

                # ë§¤ì¹­ ì •ë³´ (ì¡° ë‹¨ìœ„ë¡œ ë™ì¼)
                best_match = ""
                best_score = ""
                best_korean_text = ""
                best_reason = ""
                if first_item.get("similar_korean"):
                    top = first_item["similar_korean"][0]
                    law_name = _korean_law_name(top.get("source", ""))
                    korean_id = top['korean_id']
                    # "2" â†’ "ì œ2ì¡°" í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    if not korean_id.startswith("ì œ"):
                        korean_id = f"ì œ{korean_id}ì¡°"
                    best_match = f"{law_name} {korean_id}"
                    best_score = f"{top['score']:.3f}"
                    best_korean_text = top.get("korean_text", "")
                    best_reason = top.get("ai_reason", "")

                # ì¡°ë¬¸ ì „ì²´ ë‚´ìš© (ì²« ë²ˆì§¸ í•­ëª©ì— í•­/í˜¸/ëª© ë²ˆí˜¸ê°€ í¬í•¨ëœ ì „ì²´ ë‚´ìš©ì´ ìˆìŒ)
                combined_original = str(first_item.get("original", ""))
                combined_gemini = str(first_item.get("gemini", ""))
                combined_claude = str(first_item.get("claude", ""))
                combined_diff = first_item.get("diff_summary", "-")

                row = {"êµ­ê°€": trans_country}
                row["í¸"] = first_item.get("í¸", "")
                row["ì¥"] = first_item.get("ì¥", "")
                row["ì ˆ"] = first_item.get("ì ˆ", "")
                row["ì¡°ë¬¸ë²ˆí˜¸"] = first_item.get("ì¡°ë¬¸ë²ˆí˜¸", "")
                row["ì¡°ë¬¸ì œëª©"] = first_item.get("ì¡°ë¬¸ì œëª©", "")

                rows_full.append({
                    **row,
                    "ì›ë¬¸": combined_original,
                    "Gemini ë²ˆì—­": combined_gemini,
                    "Claude ë²ˆì—­": combined_claude,
                    "í•´ì„ ì°¨ì´": combined_diff,
                    "ìœ ì‚¬ í•œêµ­ë²•": best_match,
                    "ë§¤ì¹­ ì ìˆ˜": best_score,
                    "í•œêµ­ë²• ì¡°ë¬¸ ë‚´ìš©": best_korean_text,
                    "ë§¤ì¹­ ì´ìœ ": best_reason,
                })
                rows_display.append({
                    **row,
                    "ì›ë¬¸": combined_original[:200] + ("..." if len(combined_original) > 200 else ""),
                    "Gemini ë²ˆì—­": combined_gemini[:200] + ("..." if len(combined_gemini) > 200 else ""),
                    "Claude ë²ˆì—­": combined_claude[:200] + ("..." if len(combined_claude) > 200 else ""),
                    "ìœ ì‚¬ í•œêµ­ë²•": best_match,
                    "ë§¤ì¹­ ì´ìœ ": best_reason,
                })

            df = pd.DataFrame(rows_full)
            df_display = pd.DataFrame(rows_display)
            st.dataframe(df_display, use_container_width=True, hide_index=True)

            # Excel ì €ì¥ (ë²ˆì—­ë¹„êµê²°ê³¼ í´ë”)
            translation_dir = _safe_join(DATA_DIR, "output", "ë²ˆì—­ë¹„êµê²°ê³¼")
            os.makedirs(translation_dir, exist_ok=True)

            excel_buffer = io.BytesIO()
            with pd.ExcelWriter(excel_buffer, engine="openpyxl") as writer:
                df.to_excel(writer, index=False, sheet_name="ë²ˆì—­ê²°ê³¼")
            excel_data = excel_buffer.getvalue()

            xlsx_path = os.path.join(translation_dir, f"{base_name}.xlsx")
            with open(xlsx_path, "wb") as f:
                f.write(excel_data)

            st.success(f"ê²°ê³¼ ìë™ ì €ì¥: {xlsx_path}")

            st.download_button("Excel ë‹¤ìš´ë¡œë“œ", excel_data, f"{base_name}.xlsx",
                                   "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", key="trans_xlsx_dl")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ì¬ë²ˆì—­ ëª¨ë“œ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    elif st.session_state.get("retranslation_started", False) and foreign_excel_selected:

        # â”€â”€ ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ íŒŒì¼ ì°¾ê¸° â”€â”€
        fname = _basename(foreign_excel_selected).replace(".xlsx", "")
        parts = fname.split("_", 2)
        if len(parts) >= 3 and parts[0] == "êµ¬ì¡°í™”":
            trans_country = parts[1]
            trans_law_name = parts[2]
        elif len(parts) >= 2 and parts[0] == "êµ¬ì¡°í™”":
            trans_country = parts[1]
            trans_law_name = parts[1]
        else:
            trans_country = fname
            trans_law_name = fname

        # ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ íŒŒì¼ ê²€ìƒ‰ (í…ŒìŠ¤íŠ¸ í¬í•¨)
        existing_result = None
        for test_suffix in ["", "_í…ŒìŠ¤íŠ¸"]:
            base_name = f"ë²ˆì—­ë¹„êµ_{trans_country}_{trans_law_name}{test_suffix}"
            for search_dir in [
                _safe_join(DATA_DIR, "output", "ë²ˆì—­ë¹„êµê²°ê³¼"),
                _safe_join(DATA_DIR, "output"),
                PROJECT_DIR,
            ]:
                for ext in [".xlsx", ".csv"]:
                    candidate = _safe_join(search_dir, f"{base_name}{ext}")
                    if os.path.exists(candidate):
                        existing_result = candidate
                        break
                if existing_result:
                    break
            if existing_result:
                break

        if not existing_result:
            st.error("ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ë²ˆì—­ ì‹¤í–‰'ì„ í•´ì£¼ì„¸ìš”.")
            st.stop()

        # â”€â”€ êµ¬ì¡°í™” ì—‘ì…€ ë° ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ ë¡œë“œ â”€â”€
        try:
            df_foreign = pd.read_excel(foreign_excel_selected)
        except Exception as e:
            st.error(f"êµ¬ì¡°í™” ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨: {e}")
            st.stop()

        try:
            if existing_result.endswith((".xlsx", ".xls")):
                df_existing = pd.read_excel(existing_result)
            else:
                df_existing = pd.read_csv(existing_result, encoding="utf-8-sig")
        except Exception as e:
            st.error(f"ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            st.stop()

        st.info(f"êµ¬ì¡°í™” ì—‘ì…€: `{_basename(foreign_excel_selected)}`\n\n"
                f"ê¸°ì¡´ ë²ˆì—­ê²°ê³¼: `{_basename(existing_result)}`")

        # â”€â”€ ì¡°ë¬¸ ëª©ë¡ í‘œì‹œ (ì²´í¬ë°•ìŠ¤) â”€â”€
        st.subheader("ì¬ë²ˆì—­í•  ì¡°ë¬¸ ì„ íƒ")
        st.caption("êµ¬ì¡°í™” ì—‘ì…€ì—ì„œ ìˆ˜ì •í•œ ì¡°ë¬¸ì„ ì²´í¬í•˜ì„¸ìš”. ì„ íƒí•œ ì¡°ë¬¸ë§Œ ì¬ë²ˆì—­ + ì¬ë§¤ì¹­ë©ë‹ˆë‹¤.")

        # ì¡°ë¬¸ë²ˆí˜¸ë³„ë¡œ ê·¸ë£¹í™” (ì¤‘ë³µ ì¡°ë¬¸ë²ˆí˜¸ í•˜ë‚˜ë¡œ í‘œì‹œ)
        article_nums_seen = []
        article_info = {}
        for _, row in df_foreign.iterrows():
            art_num = str(row.get("ì¡°ë¬¸ë²ˆí˜¸", ""))
            if not art_num or art_num in article_info:
                continue
            art_title = str(row.get("ì¡°ë¬¸ì œëª©", "")) if pd.notna(row.get("ì¡°ë¬¸ì œëª©")) else ""
            article_nums_seen.append(art_num)
            article_info[art_num] = art_title

        # ì „ì²´ ì„ íƒ / í•´ì œ
        def _retrans_toggle_all():
            val = st.session_state.retrans_select_all
            for a_num in article_info:
                st.session_state[f"retrans_chk_{a_num}"] = val

        st.checkbox("ì „ì²´ ì„ íƒ", value=False, key="retrans_select_all", on_change=_retrans_toggle_all)

        selected_articles = []
        cols_per_row = 3
        article_list = list(article_info.items())

        for i in range(0, len(article_list), cols_per_row):
            cols = st.columns(cols_per_row)
            for j, col in enumerate(cols):
                idx = i + j
                if idx >= len(article_list):
                    break
                art_num, art_title = article_list[idx]
                label = f"{art_num}"
                if art_title:
                    label += f" ({art_title})"
                with col:
                    if st.checkbox(label, key=f"retrans_chk_{art_num}"):
                        selected_articles.append(art_num)

        if not selected_articles:
            st.warning("ì¬ë²ˆì—­í•  ì¡°ë¬¸ì„ ì„ íƒí•˜ì„¸ìš”.")
            st.stop()

        st.success(f"ì„ íƒëœ ì¡°ë¬¸: {len(selected_articles)}ê°œ")

        # â”€â”€ ì¬ë²ˆì—­ ì‹¤í–‰ ë²„íŠ¼ â”€â”€
        retrans_execute = st.button(
            f"ì„ íƒí•œ {len(selected_articles)}ê°œ ì¡°ë¬¸ ì¬ë²ˆì—­ + ì¬ë§¤ì¹­ ì‹¤í–‰",
            type="primary", use_container_width=True, key="retrans_execute",
        )

        if retrans_execute:
            # â”€â”€ 1) ì„ íƒí•œ ì¡°ë¬¸ë§Œ êµ¬ì¡°í™” ì—‘ì…€ì—ì„œ ì¶”ì¶œ â”€â”€
            with st.status("ì„ íƒí•œ ì¡°ë¬¸ ë¡œë“œ ì¤‘...", expanded=True) as status:
                # NaN ì±„ìš°ê¸°
                for col in ["í¸", "ì¥", "ì ˆ", "ì¡°ë¬¸ì œëª©", "í•­", "í˜¸"]:
                    if col in df_foreign.columns:
                        df_foreign[col] = df_foreign[col].fillna("").astype(str)
                    else:
                        df_foreign[col] = ""

                retrans_articles = []
                for _, row in df_foreign.iterrows():
                    art_num = str(row.get("ì¡°ë¬¸ë²ˆí˜¸", ""))
                    if art_num not in selected_articles:
                        continue

                    article_id = f"{row['ì¡°ë¬¸ë²ˆí˜¸']}"
                    if row['í•­']:
                        article_id += f"-{row['í•­']}"
                    if row['í˜¸']:
                        article_id += f"-{row['í˜¸']}"

                    text = str(row["ì›ë¬¸"]) if pd.notna(row["ì›ë¬¸"]) else ""
                    if not text.strip():
                        continue

                    retrans_articles.append({
                        "id": article_id,
                        "text": text,
                        "í¸": str(row.get("í¸", "")) if pd.notna(row.get("í¸")) else "",
                        "ì¥": str(row.get("ì¥", "")) if pd.notna(row.get("ì¥")) else "",
                        "ì ˆ": str(row.get("ì ˆ", "")) if pd.notna(row.get("ì ˆ")) else "",
                        "ì¡°ë¬¸ë²ˆí˜¸": str(row["ì¡°ë¬¸ë²ˆí˜¸"]) if pd.notna(row["ì¡°ë¬¸ë²ˆí˜¸"]) else "",
                        "ì¡°ë¬¸ì œëª©": str(row.get("ì¡°ë¬¸ì œëª©", "")) if pd.notna(row.get("ì¡°ë¬¸ì œëª©")) else "",
                        "í•­": str(row.get("í•­", "")) if pd.notna(row.get("í•­")) else "",
                        "í˜¸": str(row.get("í˜¸", "")) if pd.notna(row.get("í˜¸")) else "",
                    })

                # ì†ŒìŠ¤ ì–¸ì–´ ê²°ì •
                if source_lang_option == "ì˜ì–´":
                    source_lang = "english"
                elif source_lang_option == "ì¤‘êµ­ì–´":
                    source_lang = "chinese"
                else:
                    source_lang = _detect_lang(foreign_excel_selected)

                st.write(f"{len(retrans_articles)}ê°œ í•­ëª© ë¡œë“œ (ì†ŒìŠ¤ ì–¸ì–´: {source_lang})")
                status.update(label="ì¡°ë¬¸ ë¡œë“œ ì™„ë£Œ", state="complete")

            # â”€â”€ 2) í•œêµ­ë²• ë¡œë“œ â”€â”€
            with st.status("í•œêµ­ ë²•ë ¹ ë¡œë“œ ì¤‘...", expanded=True) as status:
                all_korea_articles = []

                for excel_path in korea_excel_selected:
                    try:
                        df_korea = pd.read_excel(excel_path)
                        source_name = _basename(excel_path)

                        korea_by_article = {}
                        for _, row in df_korea.iterrows():
                            article_num = row.get('ì¡°ë¬¸ë²ˆí˜¸', '')
                            if pd.notna(article_num) and str(article_num).strip():
                                article_num = str(article_num)
                                if article_num not in korea_by_article:
                                    korea_by_article[article_num] = {
                                        'rows': [],
                                        'title': str(row.get('ì¡°ë¬¸ì œëª©', '')).strip() if pd.notna(row.get('ì¡°ë¬¸ì œëª©')) else ""
                                    }
                                text = str(row.get("ì›ë¬¸", "")).strip()
                                if text:
                                    korea_by_article[article_num]['rows'].append(text)

                        for article_num, data in korea_by_article.items():
                            combined_text = "\n".join(data['rows'])
                            all_korea_articles.append({
                                "id": article_num,
                                "text": combined_text,
                                "source": source_name,
                                "title": data['title'],
                            })

                        st.write(f"{source_name}: {len(korea_by_article)}ê°œ ì¡°ë¬¸")
                    except Exception as e:
                        st.warning(f"ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨ ({_basename(excel_path)}): {e}")

                for kp in korea_pdf_selected:
                    k_text = parse_pdf(kp)
                    k_articles = split_articles(k_text, lang="korean")
                    for a in k_articles:
                        a["source"] = _basename(kp)
                    all_korea_articles.extend(k_articles)
                    st.write(f"{_basename(kp)}: {len(k_articles)}ê°œ ì¡°ë¬¸")

                if not all_korea_articles:
                    st.error("í•œêµ­ë²• ì¡°ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()

                korea_index = {"articles": all_korea_articles}
                st.write(f"í•œêµ­ë²• ì´ {len(all_korea_articles)}ê°œ ì¡°ë¬¸ ë¡œë“œ ì™„ë£Œ")
                status.update(label="í•œêµ­ ë²•ë ¹ ë¡œë“œ ì™„ë£Œ", state="complete")

            # â”€â”€ 3) ì„ íƒí•œ ì¡°ë¬¸ë§Œ ì¬ë²ˆì—­ â”€â”€
            st.subheader("ì¬ë²ˆì—­ ì§„í–‰")
            progress_bar = st.progress(0, text="ì¬ë²ˆì—­ ì¤€ë¹„ ì¤‘...")

            def _update_progress(current, total):
                progress_bar.progress(current / total, text=f"ì¬ë²ˆì—­ ì¤‘... ({current}/{total})")

            use_gemini = "Gemini" in translation_service
            use_claude = "Claude" in translation_service

            translated = translate_batch(
                retrans_articles,
                source_lang=source_lang,
                progress_callback=_update_progress,
                group_by_article=True,
                use_gemini=use_gemini,
                use_claude=use_claude,
            )
            progress_bar.progress(1.0, text="ì¬ë²ˆì—­ ì™„ë£Œ!")

            # â”€â”€ 4) ì„ íƒí•œ ì¡°ë¬¸ë§Œ ì¬ë§¤ì¹­ â”€â”€
            st.subheader("í•œêµ­ë²• ì¬ë§¤ì¹­")

            with st.status("ê´€ë ¨ í•œêµ­ë²• ì„ íƒ ì¤‘...", expanded=True) as status:
                korea_law_sources = sorted(set(
                    a.get("source", "") for a in all_korea_articles if a.get("source")
                ))
                sample_text = ""
                for item in translated:
                    if item["id"] != "ì „ë¬¸" and not item["id"].endswith("(ì‚­ì œ)"):
                        sample_text = item.get("gemini", "") or item.get("claude", "")
                        break

                relevant_sources = select_relevant_korean_laws(
                    _basename(foreign_excel_selected), sample_text, korea_law_sources,
                )
                for src in relevant_sources:
                    st.write(f"ê´€ë ¨ í•œêµ­ë²•: {_korean_law_name(src)}")
                status.update(label=f"ê´€ë ¨ í•œêµ­ë²• {len(relevant_sources)}ê°œ ì„ íƒ ì™„ë£Œ", state="complete")

            from collections import defaultdict
            article_groups = defaultdict(list)
            for item in translated:
                article_num = item.get("ì¡°ë¬¸ë²ˆí˜¸", item["id"])
                article_groups[article_num].append(item)

            match_progress = st.progress(0, text="í•œêµ­ë²• ì¡°ë¬¸ ì¬ë§¤ì¹­ ì¤‘...")

            batch_articles = []
            for article_num, group in article_groups.items():
                if article_num != "ì „ë¬¸" and not article_num.endswith("(ì‚­ì œ)"):
                    first_item = group[0]
                    batch_articles.append({
                        'id': article_num,
                        'text': str(first_item.get("original", "")),
                        'ì¡°ë¬¸ì œëª©': first_item.get("ì¡°ë¬¸ì œëª©", ""),
                        'translated': str(first_item.get("gemini", "")) or str(first_item.get("claude", ""))
                    })

            match_progress.progress(0.5, text="í•œêµ­ë²• ì¡°ë¬¸ ì¬ë§¤ì¹­ ì¤‘... (AI ì²˜ë¦¬ ì¤‘)")
            batch_results = find_similar_korean_batch(
                batch_articles, korea_index, relevant_law_sources=relevant_sources
            )

            for article_num, group in article_groups.items():
                if article_num == "ì „ë¬¸" or article_num.endswith("(ì‚­ì œ)"):
                    for item in group:
                        item["similar_korean"] = []
                else:
                    search_key = str(article_num)
                    for prefix in ["Article ", "Rule ", "ç¬¬"]:
                        if search_key.startswith(prefix):
                            search_key = search_key[len(prefix):]
                            break
                    search_key = search_key.rstrip("æ¢")
                    matches = batch_results.get(search_key, [])
                    if not matches:
                        matches = batch_results.get(str(article_num), [])
                    for item in group:
                        item["similar_korean"] = matches

            match_progress.progress(1.0, text="ì¬ë§¤ì¹­ ì™„ë£Œ!")

            # â”€â”€ 5) ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ Excel ì—…ë°ì´íŠ¸ â”€â”€
            st.subheader("ê²°ê³¼ ì—…ë°ì´íŠ¸")

            # ì¬ë²ˆì—­ëœ ì¡°ë¬¸ìœ¼ë¡œ ìƒˆ í–‰ ìƒì„±
            new_rows = {}
            for article_num, group in article_groups.items():
                first_item = group[0]

                best_match = ""
                best_score = ""
                best_korean_text = ""
                best_reason = ""
                if first_item.get("similar_korean"):
                    top = first_item["similar_korean"][0]
                    law_name = _korean_law_name(top.get("source", ""))
                    korean_id = top['korean_id']
                    if not korean_id.startswith("ì œ"):
                        korean_id = f"ì œ{korean_id}ì¡°"
                    best_match = f"{law_name} {korean_id}"
                    best_score = f"{top['score']:.3f}"
                    best_korean_text = top.get("korean_text", "")
                    best_reason = top.get("ai_reason", "")

                combined_original = str(first_item.get("original", ""))
                combined_gemini = str(first_item.get("gemini", ""))
                combined_claude = str(first_item.get("claude", ""))
                combined_diff = first_item.get("diff_summary", "-")

                new_rows[str(article_num)] = {
                    "êµ­ê°€": trans_country,
                    "í¸": first_item.get("í¸", ""),
                    "ì¥": first_item.get("ì¥", ""),
                    "ì ˆ": first_item.get("ì ˆ", ""),
                    "ì¡°ë¬¸ë²ˆí˜¸": first_item.get("ì¡°ë¬¸ë²ˆí˜¸", ""),
                    "ì¡°ë¬¸ì œëª©": first_item.get("ì¡°ë¬¸ì œëª©", ""),
                    "ì›ë¬¸": combined_original,
                    "Gemini ë²ˆì—­": combined_gemini,
                    "Claude ë²ˆì—­": combined_claude,
                    "í•´ì„ ì°¨ì´": combined_diff,
                    "ìœ ì‚¬ í•œêµ­ë²•": best_match,
                    "ë§¤ì¹­ ì ìˆ˜": best_score,
                    "í•œêµ­ë²• ì¡°ë¬¸ ë‚´ìš©": best_korean_text,
                    "ë§¤ì¹­ ì´ìœ ": best_reason,
                }

            # ê¸°ì¡´ DataFrameì—ì„œ í•´ë‹¹ ì¡°ë¬¸ í–‰ êµì²´
            updated_count = 0
            for idx, row in df_existing.iterrows():
                art_num = str(row.get("ì¡°ë¬¸ë²ˆí˜¸", ""))
                if art_num in new_rows:
                    for col, val in new_rows[art_num].items():
                        if col in df_existing.columns:
                            df_existing.at[idx, col] = val
                    updated_count += 1

            # ê¸°ì¡´ íŒŒì¼ì— ë®ì–´ì“°ê¸° ì €ì¥
            excel_buffer = io.BytesIO()
            with pd.ExcelWriter(excel_buffer, engine="openpyxl") as writer:
                df_existing.to_excel(writer, index=False, sheet_name="ë²ˆì—­ê²°ê³¼")
            excel_data = excel_buffer.getvalue()

            with open(existing_result, "wb") as f:
                f.write(excel_data)

            st.success(
                f"ì¬ë²ˆì—­ ì™„ë£Œ â€” {updated_count}ê°œ ì¡°ë¬¸ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"
                f"ì €ì¥: `{_basename(existing_result)}`"
            )

            # ì—…ë°ì´íŠ¸ëœ ì¡°ë¬¸ ë¯¸ë¦¬ë³´ê¸°
            st.subheader("ì—…ë°ì´íŠ¸ëœ ì¡°ë¬¸")
            updated_df = df_existing[df_existing["ì¡°ë¬¸ë²ˆí˜¸"].astype(str).isin(selected_articles)]
            if not updated_df.empty:
                display_cols = ["ì¡°ë¬¸ë²ˆí˜¸", "ì¡°ë¬¸ì œëª©", "ì›ë¬¸", "Gemini ë²ˆì—­", "Claude ë²ˆì—­", "ìœ ì‚¬ í•œêµ­ë²•"]
                display_cols = [c for c in display_cols if c in updated_df.columns]
                preview = updated_df[display_cols].copy()
                for col in ["ì›ë¬¸", "Gemini ë²ˆì—­", "Claude ë²ˆì—­"]:
                    if col in preview.columns:
                        preview[col] = preview[col].apply(
                            lambda x: str(x)[:150] + "..." if pd.notna(x) and len(str(x)) > 150 else x
                        )
                st.dataframe(preview, use_container_width=True, hide_index=True)

            st.download_button(
                "ì—…ë°ì´íŠ¸ëœ Excel ë‹¤ìš´ë¡œë“œ", excel_data,
                _basename(existing_result),
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key="retrans_dl",
            )

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ì¬ë§¤ì¹­ ëª¨ë“œ (ë²ˆì—­ì€ ìœ ì§€, ìœ ì‚¬ ì¡°ë¬¸ ë§¤ì¹­ë§Œ ë‹¤ì‹œ)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    elif st.session_state.get("rematch_started", False) and foreign_excel_selected:

        # â”€â”€ ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ íŒŒì¼ ì°¾ê¸° â”€â”€
        fname = _basename(foreign_excel_selected).replace(".xlsx", "")
        parts = fname.split("_", 2)
        if len(parts) >= 3 and parts[0] == "êµ¬ì¡°í™”":
            trans_country = parts[1]
            trans_law_name = parts[2]
        elif len(parts) >= 2 and parts[0] == "êµ¬ì¡°í™”":
            trans_country = parts[1]
            trans_law_name = parts[1]
        else:
            trans_country = fname
            trans_law_name = fname

        existing_result = None
        for test_suffix in ["", "_í…ŒìŠ¤íŠ¸"]:
            base_name = f"ë²ˆì—­ë¹„êµ_{trans_country}_{trans_law_name}{test_suffix}"
            for search_dir in [
                _safe_join(DATA_DIR, "output", "ë²ˆì—­ë¹„êµê²°ê³¼"),
                _safe_join(DATA_DIR, "output"),
                PROJECT_DIR,
            ]:
                for ext in [".xlsx", ".csv"]:
                    candidate = _safe_join(search_dir, f"{base_name}{ext}")
                    if os.path.exists(candidate):
                        existing_result = candidate
                        break
                if existing_result:
                    break
            if existing_result:
                break

        if not existing_result:
            st.error("ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ë²ˆì—­ ì‹¤í–‰'ì„ í•´ì£¼ì„¸ìš”.")
            st.stop()

        # â”€â”€ ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ ë¡œë“œ â”€â”€
        try:
            if existing_result.endswith((".xlsx", ".xls")):
                df_existing = pd.read_excel(existing_result)
            else:
                df_existing = pd.read_csv(existing_result, encoding="utf-8-sig")
        except Exception as e:
            st.error(f"ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            st.stop()

        st.info(f"ê¸°ì¡´ ë²ˆì—­ê²°ê³¼: `{_basename(existing_result)}`")

        # â”€â”€ ì¡°ë¬¸ ëª©ë¡ í‘œì‹œ (ì²´í¬ë°•ìŠ¤) â”€â”€
        st.subheader("ì¬ë§¤ì¹­í•  ì¡°ë¬¸ ì„ íƒ")
        st.caption("ìœ ì‚¬ í•œêµ­ë²• ë§¤ì¹­ì„ ë‹¤ì‹œ ì‹¤í–‰í•  ì¡°ë¬¸ì„ ì²´í¬í•˜ì„¸ìš”. ë²ˆì—­ì€ ê·¸ëŒ€ë¡œ ìœ ì§€ë©ë‹ˆë‹¤.")

        # ì¡°ë¬¸ë²ˆí˜¸ ëª©ë¡ ì¶”ì¶œ
        article_info = {}
        if "ì¡°ë¬¸ë²ˆí˜¸" in df_existing.columns:
            for _, row in df_existing.iterrows():
                art_num = str(row.get("ì¡°ë¬¸ë²ˆí˜¸", ""))
                if not art_num or art_num in article_info:
                    continue
                art_title = str(row.get("ì¡°ë¬¸ì œëª©", "")) if pd.notna(row.get("ì¡°ë¬¸ì œëª©")) else ""
                article_info[art_num] = art_title

        if not article_info:
            st.error("ë²ˆì—­ê²°ê³¼ì—ì„œ ì¡°ë¬¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        def _rematch_toggle_all():
            val = st.session_state.rematch_select_all
            for a_num in article_info:
                st.session_state[f"rematch_chk_{a_num}"] = val

        st.checkbox("ì „ì²´ ì„ íƒ", value=False, key="rematch_select_all", on_change=_rematch_toggle_all)

        selected_articles = []
        cols_per_row = 3
        article_list = list(article_info.items())

        for i in range(0, len(article_list), cols_per_row):
            cols = st.columns(cols_per_row)
            for j, col in enumerate(cols):
                idx = i + j
                if idx >= len(article_list):
                    break
                art_num, art_title = article_list[idx]
                label = f"{art_num}"
                if art_title:
                    label += f" ({art_title})"
                with col:
                    if st.checkbox(label, key=f"rematch_chk_{art_num}"):
                        selected_articles.append(art_num)

        if not selected_articles:
            st.warning("ì¬ë§¤ì¹­í•  ì¡°ë¬¸ì„ ì„ íƒí•˜ì„¸ìš”.")
            st.stop()

        st.success(f"ì„ íƒëœ ì¡°ë¬¸: {len(selected_articles)}ê°œ")

        rematch_execute = st.button(
            f"ì„ íƒí•œ {len(selected_articles)}ê°œ ì¡°ë¬¸ ì¬ë§¤ì¹­ ì‹¤í–‰",
            type="primary", use_container_width=True, key="rematch_execute",
        )

        if rematch_execute:
            # â”€â”€ 1) í•œêµ­ë²• ë¡œë“œ â”€â”€
            with st.status("í•œêµ­ ë²•ë ¹ ë¡œë“œ ì¤‘...", expanded=True) as status:
                all_korea_articles = []

                for excel_path in korea_excel_selected:
                    try:
                        df_korea = pd.read_excel(excel_path)
                        source_name = _basename(excel_path)

                        korea_by_article = {}
                        for _, row in df_korea.iterrows():
                            article_num = row.get('ì¡°ë¬¸ë²ˆí˜¸', '')
                            if pd.notna(article_num) and str(article_num).strip():
                                article_num = str(article_num)
                                if article_num not in korea_by_article:
                                    korea_by_article[article_num] = {
                                        'rows': [],
                                        'title': str(row.get('ì¡°ë¬¸ì œëª©', '')).strip() if pd.notna(row.get('ì¡°ë¬¸ì œëª©')) else ""
                                    }
                                text = str(row.get("ì›ë¬¸", "")).strip()
                                if text:
                                    korea_by_article[article_num]['rows'].append(text)

                        for article_num, data in korea_by_article.items():
                            combined_text = "\n".join(data['rows'])
                            all_korea_articles.append({
                                "id": article_num,
                                "text": combined_text,
                                "source": source_name,
                                "title": data['title'],
                            })

                        st.write(f"{source_name}: {len(korea_by_article)}ê°œ ì¡°ë¬¸")
                    except Exception as e:
                        st.warning(f"ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨ ({_basename(excel_path)}): {e}")

                for kp in korea_pdf_selected:
                    k_text = parse_pdf(kp)
                    k_articles = split_articles(k_text, lang="korean")
                    for a in k_articles:
                        a["source"] = _basename(kp)
                    all_korea_articles.extend(k_articles)
                    st.write(f"{_basename(kp)}: {len(k_articles)}ê°œ ì¡°ë¬¸")

                if not all_korea_articles:
                    st.error("í•œêµ­ë²• ì¡°ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()

                korea_index = {"articles": all_korea_articles}
                st.write(f"í•œêµ­ë²• ì´ {len(all_korea_articles)}ê°œ ì¡°ë¬¸ ë¡œë“œ ì™„ë£Œ")
                status.update(label="í•œêµ­ ë²•ë ¹ ë¡œë“œ ì™„ë£Œ", state="complete")

            # â”€â”€ 2) ì„ íƒí•œ ì¡°ë¬¸ì˜ ë²ˆì—­ë¬¸ìœ¼ë¡œ ì¬ë§¤ì¹­ â”€â”€
            st.subheader("ìœ ì‚¬ ì¡°ë¬¸ ì¬ë§¤ì¹­")

            with st.status("ê´€ë ¨ í•œêµ­ë²• ì„ íƒ ì¤‘...", expanded=True) as status:
                korea_law_sources = sorted(set(
                    a.get("source", "") for a in all_korea_articles if a.get("source")
                ))

                # ê¸°ì¡´ ë²ˆì—­ë¬¸ì—ì„œ ìƒ˜í”Œ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                sample_text = ""
                for _, row in df_existing.iterrows():
                    art_num = str(row.get("ì¡°ë¬¸ë²ˆí˜¸", ""))
                    if art_num in selected_articles:
                        sample_text = str(row.get("Gemini ë²ˆì—­", "")) or str(row.get("Claude ë²ˆì—­", ""))
                        if sample_text:
                            break

                relevant_sources = select_relevant_korean_laws(
                    _basename(foreign_excel_selected), sample_text, korea_law_sources,
                )
                for src in relevant_sources:
                    st.write(f"ê´€ë ¨ í•œêµ­ë²•: {_korean_law_name(src)}")
                status.update(label=f"ê´€ë ¨ í•œêµ­ë²• {len(relevant_sources)}ê°œ ì„ íƒ ì™„ë£Œ", state="complete")

            # ì„ íƒí•œ ì¡°ë¬¸ë§Œ ë§¤ì¹­ ëŒ€ìƒìœ¼ë¡œ êµ¬ì„±
            batch_articles = []
            for _, row in df_existing.iterrows():
                art_num = str(row.get("ì¡°ë¬¸ë²ˆí˜¸", ""))
                if art_num not in selected_articles:
                    continue
                # ì´ë¯¸ ì²˜ë¦¬í•œ ì¡°ë¬¸ë²ˆí˜¸ëŠ” ìŠ¤í‚µ (ì¤‘ë³µ ë°©ì§€)
                if any(b['id'] == art_num for b in batch_articles):
                    continue

                batch_articles.append({
                    'id': art_num,
                    'text': str(row.get("ì›ë¬¸", "")) if pd.notna(row.get("ì›ë¬¸")) else "",
                    'ì¡°ë¬¸ì œëª©': str(row.get("ì¡°ë¬¸ì œëª©", "")) if pd.notna(row.get("ì¡°ë¬¸ì œëª©")) else "",
                    'translated': str(row.get("Gemini ë²ˆì—­", "")) or str(row.get("Claude ë²ˆì—­", ""))
                })

            match_progress = st.progress(0, text="í•œêµ­ë²• ì¡°ë¬¸ ì¬ë§¤ì¹­ ì¤‘...")
            match_progress.progress(0.5, text="í•œêµ­ë²• ì¡°ë¬¸ ì¬ë§¤ì¹­ ì¤‘... (AI ì²˜ë¦¬ ì¤‘)")

            batch_results = find_similar_korean_batch(
                batch_articles, korea_index, relevant_law_sources=relevant_sources
            )

            match_progress.progress(1.0, text="ì¬ë§¤ì¹­ ì™„ë£Œ!")

            # â”€â”€ 3) ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ Excel ì—…ë°ì´íŠ¸ (ë§¤ì¹­ ì»¬ëŸ¼ë§Œ) â”€â”€
            st.subheader("ê²°ê³¼ ì—…ë°ì´íŠ¸")

            updated_count = 0
            for idx, row in df_existing.iterrows():
                art_num = str(row.get("ì¡°ë¬¸ë²ˆí˜¸", ""))
                if art_num not in selected_articles:
                    continue

                # ë§¤ì¹­ ê²°ê³¼ ì°¾ê¸°
                search_key = art_num
                for prefix in ["Article ", "Rule ", "ç¬¬"]:
                    if search_key.startswith(prefix):
                        search_key = search_key[len(prefix):]
                        break
                search_key = search_key.rstrip("æ¢")

                matches = batch_results.get(search_key, [])
                if not matches:
                    matches = batch_results.get(art_num, [])

                if matches:
                    top = matches[0]
                    law_name = _korean_law_name(top.get("source", ""))
                    korean_id = top['korean_id']
                    if not korean_id.startswith("ì œ"):
                        korean_id = f"ì œ{korean_id}ì¡°"

                    if "ìœ ì‚¬ í•œêµ­ë²•" in df_existing.columns:
                        df_existing.at[idx, "ìœ ì‚¬ í•œêµ­ë²•"] = f"{law_name} {korean_id}"
                    if "ë§¤ì¹­ ì ìˆ˜" in df_existing.columns:
                        df_existing.at[idx, "ë§¤ì¹­ ì ìˆ˜"] = f"{top['score']:.3f}"
                    if "í•œêµ­ë²• ì¡°ë¬¸ ë‚´ìš©" in df_existing.columns:
                        df_existing.at[idx, "í•œêµ­ë²• ì¡°ë¬¸ ë‚´ìš©"] = top.get("korean_text", "")
                    if "ë§¤ì¹­ ì´ìœ " in df_existing.columns:
                        df_existing.at[idx, "ë§¤ì¹­ ì´ìœ "] = top.get("ai_reason", "")
                else:
                    if "ìœ ì‚¬ í•œêµ­ë²•" in df_existing.columns:
                        df_existing.at[idx, "ìœ ì‚¬ í•œêµ­ë²•"] = ""
                    if "ë§¤ì¹­ ì ìˆ˜" in df_existing.columns:
                        df_existing.at[idx, "ë§¤ì¹­ ì ìˆ˜"] = ""
                    if "í•œêµ­ë²• ì¡°ë¬¸ ë‚´ìš©" in df_existing.columns:
                        df_existing.at[idx, "í•œêµ­ë²• ì¡°ë¬¸ ë‚´ìš©"] = ""
                    if "ë§¤ì¹­ ì´ìœ " in df_existing.columns:
                        df_existing.at[idx, "ë§¤ì¹­ ì´ìœ "] = ""

                updated_count += 1

            # ì €ì¥
            excel_buffer = io.BytesIO()
            with pd.ExcelWriter(excel_buffer, engine="openpyxl") as writer:
                df_existing.to_excel(writer, index=False, sheet_name="ë²ˆì—­ê²°ê³¼")
            excel_data = excel_buffer.getvalue()

            with open(existing_result, "wb") as f:
                f.write(excel_data)

            st.success(
                f"ì¬ë§¤ì¹­ ì™„ë£Œ â€” {updated_count}ê°œ ì¡°ë¬¸ì˜ ìœ ì‚¬ í•œêµ­ë²• ë§¤ì¹­ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"
                f"ì €ì¥: `{_basename(existing_result)}`"
            )

            # ì—…ë°ì´íŠ¸ëœ ì¡°ë¬¸ ë¯¸ë¦¬ë³´ê¸°
            st.subheader("ì—…ë°ì´íŠ¸ëœ ë§¤ì¹­ ê²°ê³¼")
            updated_df = df_existing[df_existing["ì¡°ë¬¸ë²ˆí˜¸"].astype(str).isin(selected_articles)]
            if not updated_df.empty:
                display_cols = ["ì¡°ë¬¸ë²ˆí˜¸", "ì¡°ë¬¸ì œëª©", "ìœ ì‚¬ í•œêµ­ë²•", "ë§¤ì¹­ ì ìˆ˜", "ë§¤ì¹­ ì´ìœ "]
                display_cols = [c for c in display_cols if c in updated_df.columns]
                st.dataframe(updated_df[display_cols], use_container_width=True, hide_index=True)

            st.download_button(
                "ì—…ë°ì´íŠ¸ëœ Excel ë‹¤ìš´ë¡œë“œ", excel_data,
                _basename(existing_result),
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key="rematch_dl",
            )

    elif not trans_run:
        pass

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# í˜ì´ì§€ 3: ë²ˆì—­ê²°ê³¼ ìƒì„¸ë³´ê¸°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
else:  # page == "ìƒì„¸ë³´ê¸°"
    st.markdown("""
    <div class="section-header">
        <h3>ë²ˆì—­ ê²°ê³¼ ìƒì„¸ë³´ê¸°</h3>
    </div>
    """, unsafe_allow_html=True)

    st.markdown("""
    <div class="info-card">
        <p style="margin: 0; color: #64748b;">
            ë²ˆì—­ëœ ë²•ë ¹ ì¡°ë¬¸ì„ ì›ë¬¸, Gemini ë²ˆì—­, Claude ë²ˆì—­, í•œêµ­ë²• ë§¤ì¹­ ì •ë³´ì™€ í•¨ê»˜ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.
            ì „ì²´ë³´ê¸° ë˜ëŠ” ì¡°ë¬¸ë³„ ìƒì„¸ë³´ê¸° ëª¨ë“œë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        </p>
    </div>
    """, unsafe_allow_html=True)

    st.markdown("")  # ì—¬ë°±

    result_files = _list_result_files()

    if not result_files:
        st.warning(
            "ì¡°íšŒí•  ë²ˆì—­ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\n\n"
            "'ë²ˆì—­ ì‹¤í–‰' íƒ­ì—ì„œ ë¨¼ì € ë²ˆì—­ì„ ì§„í–‰í•´ì£¼ì„¸ìš”."
        )
    else:
        selected_file = st.selectbox(
            "ê²°ê³¼ íŒŒì¼ ì„ íƒ", result_files, format_func=_basename, key="csv_viewer_select",
        )

        if selected_file:
            df_csv = None

            if selected_file:
                if selected_file.endswith((".xlsx", ".xls")):
                    try:
                        df_csv = pd.read_excel(selected_file)
                    except Exception as e:
                        st.error(f"Excel íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                else:
                    for enc in ["utf-8-sig", "utf-8", "cp949", "euc-kr"]:
                        try:
                            df_csv = pd.read_csv(selected_file, encoding=enc)
                            break
                        except (UnicodeDecodeError, UnicodeError):
                            continue

            if df_csv is None:
                st.error("íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜•ì‹ì´ë‚˜ ì¸ì½”ë”©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            else:
                display_name = _basename(selected_file)
                st.subheader(f"{display_name}")

                # ìš”ì•½ ì •ë³´
                col_info1, col_info2, col_info3 = st.columns(3)
                with col_info1:
                    st.metric("ì´ ì¡°ë¬¸ ìˆ˜", len(df_csv))
                with col_info2:
                    if "êµ­ê°€" in df_csv.columns:
                        st.metric("êµ­ê°€", df_csv["êµ­ê°€"].iloc[0] if len(df_csv) > 0 else "-")
                with col_info3:
                    if "ë§¤ì¹­ ì ìˆ˜" in df_csv.columns:
                        scores = pd.to_numeric(df_csv["ë§¤ì¹­ ì ìˆ˜"], errors="coerce")
                        avg_score = scores.mean()
                        st.metric("í‰ê·  ë§¤ì¹­ ì ìˆ˜", f"{avg_score:.3f}" if pd.notna(avg_score) else "-")

                st.divider()

                # í•„í„°ë§
                filter_col1, filter_col2 = st.columns(2)
                with filter_col1:
                    if "êµ­ê°€" in df_csv.columns:
                        countries_in_csv = ["ì „ì²´"] + sorted(df_csv["êµ­ê°€"].dropna().unique().tolist())
                        filter_country = st.selectbox("êµ­ê°€ í•„í„°", countries_in_csv, key="csv_filter_country")
                    else:
                        filter_country = "ì „ì²´"
                with filter_col2:
                    search_term = st.text_input("ì¡°ë¬¸/ë‚´ìš© ê²€ìƒ‰", key="csv_search", placeholder="ê²€ìƒ‰ì–´ ì…ë ¥...")

                df_filtered = df_csv.copy()
                if "êµ­ê°€" in df_csv.columns and filter_country != "ì „ì²´":
                    df_filtered = df_filtered[df_filtered["êµ­ê°€"] == filter_country]
                if search_term:
                    mask = df_filtered.apply(
                        lambda row: row.astype(str).str.contains(search_term, case=False, na=False).any(), axis=1,
                    )
                    df_filtered = df_filtered[mask]

                # 'ì „ë¬¸' í–‰ ì œì™¸
                if "ì¡°ë¬¸" in df_filtered.columns:
                    df_filtered = df_filtered[df_filtered["ì¡°ë¬¸"] != "ì „ë¬¸"]
                elif "ì¡°ë¬¸ë²ˆí˜¸" in df_filtered.columns:
                    # êµ¬ì¡°í™” ë°ì´í„°ëŠ” ì „ë¬¸ì´ ë”°ë¡œ ì—†ìœ¼ë¯€ë¡œ ìŠ¤í‚µ
                    pass

                st.caption(f"í‘œì‹œ ì¤‘: {len(df_filtered)}ê±´ / ì „ì²´ {len(df_csv)}ê±´")

                # ë³´ê¸° ëª¨ë“œ ì„ íƒ
                view_mode = st.radio(
                    "ë³´ê¸° ëª¨ë“œ", ["ì¡°ë¬¸ë³„ ìƒì„¸ ë³´ê¸°", "ì „ì²´ ë³´ê¸° (ë³µì‚¬ìš©)"],
                    horizontal=True, key="csv_view_mode",
                )

                st.markdown(DETAIL_STYLE, unsafe_allow_html=True)

                csv_name = display_name.replace(".csv", "").replace(".xlsx", "")
                parts = csv_name.split("_", 2)
                foreign_law_name = parts[2] if len(parts) >= 3 else csv_name

                if view_mode == "ì „ì²´ ë³´ê¸° (ë³µì‚¬ìš©)":
                    # â”€â”€ ì „ì²´ ë³´ê¸°: 3ì—´ ì •ë ¬ í…Œì´ë¸” â”€â”€
                    st.subheader("ì „ì²´ ë³´ê¸°")

                    # ë§¤ì¹­ ì •ë³´ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                    has_matching = "ìœ ì‚¬ í•œêµ­ë²•" in df_filtered.columns

                    table_html = """<table class="fullview-table">
                    <colgroup>
                        <col class="col-id">"""

                    if has_matching:
                        # í•œêµ­ë²•ì´ ìˆì„ ë•Œ: ê° í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ë„ˆë¹„ë¥¼ ì¤„ì„
                        table_html += '<col class="col-text-narrow"><col class="col-text-narrow"><col class="col-text-narrow"><col class="col-korean">'
                    else:
                        # í•œêµ­ë²•ì´ ì—†ì„ ë•Œ: ê¸°ì¡´ ë„ˆë¹„ ìœ ì§€
                        table_html += '<col class="col-text"><col class="col-text"><col class="col-text">'

                    table_html += """
                    </colgroup>
                    <thead><tr>
                        <th>ì¡°ë¬¸</th><th style="color:#8b2240">ì›ë¬¸</th>
                        <th style="color:#b8860b">Gemini ë²ˆì—­</th>
                        <th style="color:#6e1a33">Claude ë²ˆì—­</th>"""

                    if has_matching:
                        table_html += '<th style="color:#a0522d">ìœ ì‚¬ í•œêµ­ë²•</th>'

                    table_html += """
                    </tr></thead><tbody>"""

                    full_original = []
                    full_gemini = []
                    full_claude = []
                    full_korean = []

                    for _, row in df_filtered.iterrows():
                        # ì¡°ë¬¸ ID êµ¬ì„±: êµ¬ì¡°í™”ëœ ê²½ìš° ì¡°ë¬¸ë²ˆí˜¸, ì•„ë‹ˆë©´ "ì¡°ë¬¸" ì»¬ëŸ¼
                        if "ì¡°ë¬¸ë²ˆí˜¸" in row.index and pd.notna(row.get("ì¡°ë¬¸ë²ˆí˜¸")):
                            article_num = str(row['ì¡°ë¬¸ë²ˆí˜¸'])
                            # ì¡°ë¬¸ë²ˆí˜¸ í˜•ì‹ íŒë‹¨
                            if article_num.startswith(("Article", "Rule")):
                                # ì˜ë¬¸ë²•: Article N í˜•ì‹ ê·¸ëŒ€ë¡œ
                                aid = article_num
                            elif article_num.startswith("ç¬¬") and article_num.endswith("æ¢"):
                                # ì¤‘ë¬¸ë²•: ç¬¬Næ¢ í˜•ì‹ ê·¸ëŒ€ë¡œ
                                aid = article_num
                            else:
                                # í•œêµ­ë²•: ì œNì¡° í˜•ì‹
                                aid = f"ì œ{article_num}ì¡°"
                        else:
                            aid = str(row.get("ì¡°ë¬¸", ""))

                        orig = _clean_text(str(row.get("ì›ë¬¸", ""))) if pd.notna(row.get("ì›ë¬¸")) else ""
                        gem = _clean_text(_clean_translation_output(str(row.get("Gemini ë²ˆì—­", "")))) if pd.notna(row.get("Gemini ë²ˆì—­")) else ""
                        cla = _clean_text(_clean_translation_output(str(row.get("Claude ë²ˆì—­", "")))) if pd.notna(row.get("Claude ë²ˆì—­")) else ""

                        full_original.append(f"[{aid}]\n{orig}")
                        full_gemini.append(f"[{aid}]\n{gem}")
                        full_claude.append(f"[{aid}]\n{cla}")

                        # í•œêµ­ë²• ë§¤ì¹­ ì •ë³´
                        korean_info = ""
                        if has_matching:
                            similar_korean = str(row.get("ìœ ì‚¬ í•œêµ­ë²•", "")) if pd.notna(row.get("ìœ ì‚¬ í•œêµ­ë²•")) else ""

                            if similar_korean and similar_korean != "-":
                                korean_info = f"{_esc(similar_korean)}"

                            full_korean.append(f"[{aid}] {similar_korean}")

                        table_html += f"<tr><td><strong>{_esc(aid)}</strong></td>"
                        table_html += f"<td>{_esc(orig)}</td>"
                        table_html += f"<td>{_esc(gem)}</td>"
                        table_html += f"<td>{_esc(cla)}</td>"

                        if has_matching:
                            table_html += f"<td>{korean_info}</td>"

                        table_html += "</tr>"

                    table_html += "</tbody></table>"
                    st.markdown(table_html, unsafe_allow_html=True)

                    # í…ìŠ¤íŠ¸ ë³µì‚¬ìš© ì˜ì—­
                    st.divider()
                    st.subheader("í…ìŠ¤íŠ¸ ë³µì‚¬")

                    if has_matching and full_korean:
                        # ë§¤ì¹­ ì •ë³´ê°€ ìˆìœ¼ë©´ 4ì—´ë¡œ í‘œì‹œ
                        copy_col1, copy_col2, copy_col3, copy_col4 = st.columns(4)
                        with copy_col1:
                            st.text_area("ì›ë¬¸ ì „ì²´", "\n\n".join(full_original), height=400, key="copy_orig")
                        with copy_col2:
                            st.text_area("Gemini ë²ˆì—­ ì „ì²´", "\n\n".join(full_gemini), height=400, key="copy_gem")
                        with copy_col3:
                            st.text_area("Claude ë²ˆì—­ ì „ì²´", "\n\n".join(full_claude), height=400, key="copy_claude")
                        with copy_col4:
                            st.text_area("ìœ ì‚¬ í•œêµ­ë²• ì „ì²´", "\n\n".join(full_korean), height=400, key="copy_korean")
                    else:
                        # ë§¤ì¹­ ì •ë³´ê°€ ì—†ìœ¼ë©´ 3ì—´ë¡œ í‘œì‹œ
                        copy_col1, copy_col2, copy_col3 = st.columns(3)
                        with copy_col1:
                            st.text_area("ì›ë¬¸ ì „ì²´", "\n\n".join(full_original), height=400, key="copy_orig")
                        with copy_col2:
                            st.text_area("Gemini ë²ˆì—­ ì „ì²´", "\n\n".join(full_gemini), height=400, key="copy_gem")
                        with copy_col3:
                            st.text_area("Claude ë²ˆì—­ ì „ì²´", "\n\n".join(full_claude), height=400, key="copy_claude")

                else:
                    # â”€â”€ ì¡°ë¬¸ë³„ ìƒì„¸ ë³´ê¸° â”€â”€
                    st.subheader("ì¡°ë¬¸ë³„ ìƒì„¸ ë³´ê¸°")

                    has_structured = "ì¡°ë¬¸ë²ˆí˜¸" in df_filtered.columns

                    for idx, row in df_filtered.iterrows():
                        country_name = row.get("êµ­ê°€", "") if "êµ­ê°€" in row.index else ""

                        # êµ¬ì¡° ì •ë³´ êµ¬ì„±
                        structure_info = []
                        if has_structured:
                            if country_name:
                                structure_info.append(country_name)
                            elif foreign_law_name:
                                structure_info.append(foreign_law_name)
                            if "í¸" in row.index and pd.notna(row.get("í¸")) and str(row["í¸"]).strip():
                                structure_info.append(str(row["í¸"]))
                            if "ì¥" in row.index and pd.notna(row.get("ì¥")) and str(row["ì¥"]).strip():
                                structure_info.append(str(row["ì¥"]))
                            if "ì ˆ" in row.index and pd.notna(row.get("ì ˆ")) and str(row["ì ˆ"]).strip():
                                structure_info.append(str(row["ì ˆ"]))

                            # ì¡°ë¬¸ë²ˆí˜¸ í˜•ì‹ íŒë‹¨ (í•œêµ­ë²•: ìˆ«ìë§Œ, ì˜ë¬¸ë²•: Article N, ì¤‘ë¬¸ë²•: ç¬¬Næ¢)
                            article_num = str(row.get('ì¡°ë¬¸ë²ˆí˜¸', ''))
                            if article_num.startswith(("Article", "Rule")):
                                # ì˜ë¬¸ë²•: Article N í˜•ì‹ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                                art_label = article_num
                            elif article_num.startswith("ç¬¬") and article_num.endswith("æ¢"):
                                # ì¤‘ë¬¸ë²•: ç¬¬Næ¢ í˜•ì‹ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                                art_label = article_num
                            elif country_name in ("ë‰´ì§ˆëœë“œ", "í™ì½©"):
                                # ì˜ë¯¸ë²• êµ­ê°€: Section N í˜•ì‹
                                art_label = f"Section {article_num}"
                            else:
                                # í•œêµ­ë²•: ì œNì¡° í˜•ì‹
                                art_label = f"ì œ{article_num}ì¡°"

                            if "ì¡°ë¬¸ì œëª©" in row.index and pd.notna(row.get("ì¡°ë¬¸ì œëª©")) and str(row["ì¡°ë¬¸ì œëª©"]).strip():
                                art_label += f" {row['ì¡°ë¬¸ì œëª©']}"
                            structure_info.append(art_label)
                        else:
                            article_id = row.get("ì¡°ë¬¸", f"í–‰ {idx}")
                            if country_name:
                                structure_info.append(f"{country_name} {foreign_law_name} â€” {article_id}")
                            else:
                                structure_info.append(f"{foreign_law_name} â€” {article_id}")

                        structure_text = " â€” ".join(structure_info)
                        original_text = _esc(_clean_text(str(row["ì›ë¬¸"]))) if "ì›ë¬¸" in row.index and pd.notna(row["ì›ë¬¸"]) else ""
                        gemini_text = _esc(_clean_text(_clean_translation_output(str(row["Gemini ë²ˆì—­"])))) if "Gemini ë²ˆì—­" in row.index and pd.notna(row.get("Gemini ë²ˆì—­")) else ""
                        claude_text = _esc(_clean_text(_clean_translation_output(str(row["Claude ë²ˆì—­"])))) if "Claude ë²ˆì—­" in row.index and pd.notna(row.get("Claude ë²ˆì—­")) else ""

                        # êµ¬ì¡° ì •ë³´ë¥¼ ìœ„ì— í‘œì‹œ
                        st.markdown(f'<div class="article-title">{structure_text}</div>', unsafe_allow_html=True)
                        st.markdown(f"""
                        <div class="article-row">
                            <div class="article-col col-original"><div class="article-col-header">ì›ë¬¸</div><div class="article-col-body">{original_text}</div></div>
                            <div class="article-col col-gemini"><div class="article-col-header">Gemini ë²ˆì—­</div><div class="article-col-body">{gemini_text}</div></div>
                            <div class="article-col col-claude"><div class="article-col-header">Claude ë²ˆì—­</div><div class="article-col-body">{claude_text}</div></div>
                        </div>
                        """, unsafe_allow_html=True)

                        # ìœ ì‚¬ í•œêµ­ë²•
                        if "ìœ ì‚¬ í•œêµ­ë²•" in row.index and pd.notna(row.get("ìœ ì‚¬ í•œêµ­ë²•")) and str(row["ìœ ì‚¬ í•œêµ­ë²•"]).strip():
                            korean_article = str(row["ìœ ì‚¬ í•œêµ­ë²•"])
                            if not korean_article.startswith("["):
                                korean_article = f"[í•œêµ­ë²•] {korean_article}"
                            score_str = f" (ìœ ì‚¬ë„: {row['ë§¤ì¹­ ì ìˆ˜']})" if "ë§¤ì¹­ ì ìˆ˜" in row.index and pd.notna(row.get("ë§¤ì¹­ ì ìˆ˜")) else ""
                            korean_text_html = ""
                            if "í•œêµ­ë²• ì¡°ë¬¸ ë‚´ìš©" in row.index and pd.notna(row.get("í•œêµ­ë²• ì¡°ë¬¸ ë‚´ìš©")) and str(row["í•œêµ­ë²• ì¡°ë¬¸ ë‚´ìš©"]).strip():
                                korean_text_html = f"<br><div style='margin-top:6px;white-space:pre-wrap;color:#333;'>{_esc(_clean_text(str(row['í•œêµ­ë²• ì¡°ë¬¸ ë‚´ìš©'])))}</div>"
                            st.markdown(f'<div class="korea-law-box"><strong>ìœ ì‚¬ í•œêµ­ë²•: {korean_article}{score_str}</strong>{korean_text_html}</div>', unsafe_allow_html=True)

                            # ë§¤ì¹­ ì´ìœ 
                            if "ë§¤ì¹­ ì´ìœ " in row.index and pd.notna(row.get("ë§¤ì¹­ ì´ìœ ")) and str(row["ë§¤ì¹­ ì´ìœ "]).strip():
                                st.markdown(f'<div class="diff-box"><strong>ë§¤ì¹­ ì´ìœ </strong><br>{_esc(str(row["ë§¤ì¹­ ì´ìœ "]))}</div>', unsafe_allow_html=True)

                        # í•´ì„ ì°¨ì´
                        if "í•´ì„ ì°¨ì´" in row.index and pd.notna(row.get("í•´ì„ ì°¨ì´")) and str(row["í•´ì„ ì°¨ì´"]).strip() not in ("", "-"):
                            diff_text = _esc(_clean_text(str(row["í•´ì„ ì°¨ì´"])))
                            st.markdown(f'<div class="diff-box"><strong>í•´ì„ ì°¨ì´</strong><br>{diff_text}</div>', unsafe_allow_html=True)

                        st.markdown("<br>", unsafe_allow_html=True)
                        st.divider()

                # Excel ë‹¤ìš´ë¡œë“œ
                st.divider()
                download_base = csv_name

                excel_buf = io.BytesIO()
                with pd.ExcelWriter(excel_buf, engine="openpyxl") as ew:
                    df_filtered.to_excel(ew, index=False, sheet_name="ë²ˆì—­ê²°ê³¼")
                excel_download = excel_buf.getvalue()

                st.download_button("Excel ë‹¤ìš´ë¡œë“œ", excel_download, f"{download_base}.xlsx",
                                   "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", key="xlsx_dl")
